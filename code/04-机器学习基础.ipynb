{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前面的学习，我们已经知道如何用神经网络解决分类问题和回归问题，而且也看到了机器学习的核心难题：**过拟合**。\n",
    "\n",
    "本章会将你对这些问题的直觉固化为解决深度学习问题的可靠的概念框架。我们将把所有这些概念——\n",
    "**模型评估、数据预处理、特征工程、解决过拟合**——整合为详细的七步工作流程，用来解决任何机器学习任务。\n",
    "\n",
    "# 1 机器学习的四个分支\n",
    "\n",
    "* **监督学习**：是当前深度学习的主要形式，行业应用非常广泛。\n",
    "    * 分类\n",
    "    * 回归\n",
    "    * **序列生成（sequence generation）**。给定一张图像，预测描述图像的文字。序列生成有时可以被重新表示为一系列分类问题，比如反复预测序列中的单词或标记。\n",
    "    * **语法树预测（syntax tree prediction）**。给定一个句子，预测其分解生成的语法树。\n",
    "    * **目标检测（object detection）**。给定一张图像，在图中特定目标的周围画一个边界框。这个问题也可以表示为分类问题（给定多个候选边界框，对每个框内的目标进行分类）或分类与回归联合问题（用向量回归来预测边界框的坐标）。\n",
    "    * **图像分割（image segmentation）**。给定一张图像，在特定物体上画一个像素级的掩模（mask）。\n",
    "    \n",
    "* **无监督学习**\n",
    "    * 降维（dimensionality reduction）\n",
    "    * 聚类（clustering）\n",
    "    \n",
    "* **自监督学习**：自监督学习是监督学习的一个特例，它与众不同，值得单独归为一类。自监督学习是没有人工标注的标签的监督学习，你可以将它看作没有人类参与的监督学习。标签仍然存在（因为总要有什么东西来监督学习过程），但它们是从输入数据中生成的，通常是使用启发式算法生成的。\n",
    "    * **自编码器（autoencoder）是有名的自监督学习的例子，其生成的目标就是未经修改的输入**。同样，给定视频中过去的帧来预测下一帧，或者给定文本中前面的词来预测下一个词，都是自监督学习的例子［这两个例子也属于**时序监督学习（temporally supervised learning）， 即用未来的输入数据作为监督］**。注意，**监督学习、自监督学习和无监督学习**之间的区别有时很模糊，这三个类别更像是没有明确界限的连续体。**自监督学习可以被重新解释为监督学习或无监督学习，这取决于你关注的是学习机制还是应用场景**。\n",
    "    \n",
    "* **强化学习**：智能体（agent）接收有关其环境的信息，并学会选择使某种奖励最大化的行动。强化学习主要集中在研究领域，除游戏外还没有取得实践上的重大成功。但是，我们期待强化学习未来能够实现越来越多的实际应用：自动驾驶汽车、机器人、资源管理、教育等。强化学习的时代已经到来，或即将到来。\n",
    "\n",
    "![image.png](../img/04/术语.png)\n",
    "\n",
    "# 2 评估机器学习模型\n",
    "\n",
    "我们将数据划分为**训练集、验证集和测试集**。我们没有在训练模型的相同数据上对模型进行评估，其原因很快显而易见：仅仅几轮过后，三个模型都开始过拟合。也就是说，随着训练的进行，模型在训练数据上的性能始终在提高，但在前所未见的数据上的性能则不再变化或者开始下降。\n",
    "\n",
    "机器学习的目的是得到可以泛化（generalize）的模型，即在前所未见的数据上表现很好的模型，而过拟合则是核心难点。你只能控制可以观察的事情，所以能够可靠地衡量模型的泛化能力非常重要。后面几节将介绍降低过拟合以及将泛化能力最大化的方法。\n",
    "\n",
    "本节重点介绍**如何衡量泛化能力，即如何评估机器学习模型**。\n",
    "\n",
    "## 2.1 训练集、验证集和测试集\n",
    "\n",
    "* 评估模型的重点是将数据划分为三个集合：训练集、验证集和测试集。**在训练数据上训练模型，在验证数据上评估模型。一旦找到了最佳参数，就在测试数据上最后测试一次**。\n",
    "\n",
    "* 你可能会问，**为什么不是两个集合**：**一个训练集和一个测试集？在训练集上训练模型，然后在测试集上评估模型。这样简单得多！**\n",
    "\n",
    "* 原因在于**开发模型时总是需要调节模型配置**，比如**选择层数或每层大小［这叫作模型的超参数（hyperparameter），以便与模型参数（即权重）区分开］**。这个调节过程**需要使用模型在验证数据上的性能作为反馈信号**。这个调节过程本质上就是一种学习：**在某个参数空间中寻找良好的模型配置**。因此，**如果基于模型在验证集上的性能来调节模型配置，会很快导致模型在验证集上过拟合，即使你并没有在验证集上直接训练模型也会如此**。\n",
    "\n",
    "* 造成这一现象的关键在于**信息泄露（information leak）**。**每次基于模型在验证集上的性能来调节模型超参数，都会有一些关于验证数据的信息泄露到模型中**。**如果对每个参数只调节一次，那么泄露的信息很少，验证集仍然可以可靠地评估模型。但如果你多次重复这一过程（运行一次实验，在验证集上评估，然后据此修改模型），那么将会有越来越多的关于验证集的信息泄露到模型中。**\n",
    "\n",
    "* 最后，你得到的模型在验证集上的性能非常好（人为造成的），因为这正是你优化的目的。你关心的是模型在全新数据上的性能，而不是在验证数据上的性能，因此你需要使用一个完全不同的、前所未见的数据集来评估模型，它就是测试集。**你的模型一定不能读取与测试集有关的任何信息，既使间接读取也不行**。**如果基于测试集性能来调节模型，那么对泛化能力的衡量是不准确的**。**将数据划分为训练集、验证集和测试集可能看起来很简单，但如果可用数据很少，还有几种高级方法可以派上用场**。我们先来介绍三种经典的评估方法：**简单的留出验证**、 **K 折验证**，以及**带有打乱数据的重复 K 折验证**。\n",
    "\n",
    "**1. 简单的留出验证**\n",
    "\n",
    "留出一定比例的数据作为测试集。在剩余的数据上训练模型，然后在测试集上评估模型。如前所述，为了防止信息泄露，你不能基于测试集来调节模型，所以还应该保留一个验证集。留出验证（hold-out validation）的示意图见图\n",
    "\n",
    "![image.png](../img/04/留出验证.png)\n",
    "\n",
    "```python\n",
    "num_validation_samples = 10000\n",
    "\n",
    "# 通常需要打乱数据\n",
    "np.random.shuffle(data) \n",
    "\n",
    "# 定义验证集\n",
    "validation_data = data[:num_validation_samples]\n",
    "data = data[num_validation_samples:]\n",
    "\n",
    "# 定义训练集\n",
    "training_data = data[:]\n",
    "\n",
    "# 在训练数据上训练模型，并在验证数据上评估模型\n",
    "model = get_model()\n",
    "model.train(training_data)\n",
    "validation_score = model.evaluate(validation_data)\n",
    "\n",
    "# 现在你可以调节模型、重新训练、评估，然后再次调节……\n",
    "# 一旦调节好超参数，通常就在所有非测试数据上从头开始训练最终模型\n",
    "model = get_model()\n",
    "model.train(np.concatenate([training_data,validation_data]))\n",
    "test_score = model.evaluate(test_data)\n",
    "```\n",
    "\n",
    "> 有一个缺点：如果可用的数据很少，那么可能验证集和测试集包含的样本就太少，从而无法在统计学上代表数据。这个问题很\n",
    "容易发现：如果在划分数据前进行不同的随机打乱，最终得到的模型性能差别很大，那么就存在这个问题。\n",
    "\n",
    "**2. K 折验证**\n",
    "\n",
    "K 折验证（K-fold validation）将数据划分为大小相同的 K 个分区。 对于每个分区 i，在剩余的 K-1 个分区上训练模型，然后在分区 i 上评估模型。最终分数等于 K 个分数的平均值。对于不同的训练集 - 测试集划分，如果模型性能的变化很大，那么这种方法很有用。与留出验证一样，这种方法也需要独立的验证集进行模型校正。K 折交叉验证的示意图见图\n",
    "\n",
    "![image.png](../img/04/三折验证.png)\n",
    "\n",
    "```python\n",
    "k = 4\n",
    "num_validation_samples = len(data) // k\n",
    "\n",
    "np.random.shuffle(data)\n",
    "\n",
    "validation_scores = []\n",
    "for fold in range(k):\n",
    "    # 选择验证数据分区\n",
    "    validation_data = data[num_validation_samples * fold:num_validation_samples * (fold + 1)]\n",
    "    # 使用剩余数据作为训练数据。注意，+ 运算符是列表合并，不是求和\n",
    "    training_data = data[:num_validation_samples * fold] + data[num_validation_samples * (fold + 1):]\n",
    "    \n",
    "    # 创建一个全新的模型实例（未训练）\n",
    "    model = get_model()\n",
    "    model.train(training_data)\n",
    "    validation_score = model.evaluate(validation_data)\n",
    "    validation_scores.append(validation_score)\n",
    "\n",
    "# 最终验证分数： K 折验证分数的平均值\n",
    "validation_score = np.average(validation_scores)\n",
    "\n",
    "# 在所有非测试数据上训练最终模型\n",
    "model = get_model()\n",
    "model.train(data)\n",
    "test_score = model.evaluate(test_data)\n",
    "```\n",
    "\n",
    "**3. 带有打乱数据的重复 K 折验证**\n",
    "\n",
    "**如果可用的数据相对较少，而你又需要尽可能精确地评估模型，那么可以选择带有打乱数据的重复 K 折验证（iterated K-fold validation with shuffling）**。我发现这种方法在 Kaggle 竞赛中特别有用。具体做法是**多次使用 K 折验证，在每次将数据划分为 K 个分区之前都先将数据打乱。最终分数是每次 K 折验证分数的平均值**。注意，这种方法**一共要训练和评估 P×K 个模型（P是重复次数），计算代价很大**。\n",
    "\n",
    "## 2.2 评估模型的注意事项\n",
    "\n",
    "选择模型评估方法时，需要注意以下几点。\n",
    "\n",
    "* **数据代表性（data representativeness）**。你希望训练集和测试集都能够代表当前数据。例如，你想要对数字图像进行分类，而图像样本是按类别排序的，如果你将前 80% 作为训练集，剩余 20% 作为测试集，那么会导致训练集中只包含类别 0~7，而测试集中只包含类别 8~9。这个错误看起来很可笑，却很常见。因此，**在将数据划分为训练集和测试集之前，通常应该随机打乱数据**。\n",
    "\n",
    "* **时间箭头（the arrow of time）**。如果想要根据过去预测未来（比如明天的天气、股票走势等），那么在**划分数据前你不应该随机打乱数据，因为这么做会造成时间泄露（temporalleak）**：你的模型将**在未来数据上得到有效训练**。在这种情况下，你**应该始终确保测试集中所有数据的时间都晚于训练集数据**。\n",
    "\n",
    "* **数据冗余（redundancy in your data）**。如果**数据中的某些数据点出现了两次**（这在现实中的数据里十分常见），那么**打乱数据并划分成训练集和验证集会导致训练集和验证集之间的数据冗余**。从效果上来看，你是**在部分训练数据上评估模型，这是极其糟糕的！一定要确保训练集和验证集之间没有交集**。\n",
    "\n",
    "# 3 数据预处理、特征工程和特征学习\n",
    "\n",
    "除模型评估之外，在深入研究模型开发之前，我们还必须解决另一个重要问题：将数据输入神经网络之前，如何准备输入数据和目标？许多数据预处理方法和特征工程技术都是和特定领域相关的（比如只和文本数据或图像数据相关）\n",
    "\n",
    "## 3.1 神经网络的数据预处理\n",
    "\n",
    "数据预处理的目的是使原始数据更适于用神经网络处理，包括向量化、标准化、处理缺失值和特征提取。\n",
    "\n",
    "**1. 向量化**\n",
    "\n",
    "神经网络的所有输入和目标都必须是浮点数张量（在特定情况下可以是整数张量）。无论处理什么数据（声音、图像还是文本），都必须首先将其转换为张量，这一步叫作数据向量化（data vectorization）。例如，在前面两个文本分类的例子中，开始时文本都表示为整数列表（代表单词序列），然后我们用 one-hot 编码将其转换为 float32 格式的张量。在手写数字分类和预测房价的例子中，数据已经是向量形式，所以可以跳过这一步。\n",
    "\n",
    "**2. 值标准化**\n",
    "\n",
    "在手写数字分类的例子中，开始时图像数据被编码为 0~255 范围内的整数，表示灰度值。将这一数据输入网络之前，你需要将其转换为 float32 格式并除以 255，这样就得到 0~1 范围内的浮点数。同样，预测房价时，开始时特征有各种不同的取值范围，有些特征是较小的浮点数，\n",
    "\n",
    "有些特征是相对较大的整数。将这一数据输入网络之前，你需要对每个特征分别做标准化，使\n",
    "其均值为 0、标准差为 1。\n",
    "\n",
    "一般来说，将取值相对较大的数据（比如多位整数，比网络权重的初始值大很多）或异质数据（heterogeneous data，比如数据的一个特征在 0~1 范围内，另一个特征在 100~200 范围内）输入到神经网络中是不安全的。这么做可能导致较大的梯度更新，进而导致网络无法收敛。为了让网络的学习变得更容易，输入数据应该具有以下特征。\n",
    "\n",
    "    * 取值较小：大部分值都应该在 0~1 范围内。\n",
    "    * 同质性（homogenous）：所有特征的取值都应该在大致相同的范围内。\n",
    "\n",
    "此外，下面这种更严格的标准化方法也很常见，而且很有用，虽然不一定总是必需的（例如，对于数字分类问题就不需要这么做）。\n",
    "\n",
    "    * 将每个特征分别标准化，使其平均值为 0。\n",
    "    * 将每个特征分别标准化，使其标准差为 1。\n",
    "    \n",
    "这对于 Numpy 数组很容易实现。\n",
    "\n",
    "```python\n",
    "# 假设 x 是一个形状为 (samples,features) 的二维矩阵\n",
    "x -= x.mean(axis=0)\n",
    "x /= x.std(axis=0)\n",
    "```\n",
    "\n",
    "**3. 处理缺失值**\n",
    "\n",
    "你的数据中有时可能会有缺失值。例如在房价的例子中，第一个特征（数据中索引编号为0 的列）是人均犯罪率。如果不是所有样本都具有这个特征的话，怎么办？那样你的训练数据或测试数据将会有缺失值。\n",
    "\n",
    "一般来说，对于神经网络，将缺失值设置为 0 是安全的，只要 0 不是一个有意义的值。网络能够从数据中学到 0 意味着缺失数据，并且会忽略这个值。\n",
    "\n",
    "注意，如果测试数据中可能有缺失值，而网络是在没有缺失值的数据上训练的，那么网络不可能学会忽略缺失值。在这种情况下，你应该人为生成一些有缺失项的训练样本：多次复制一些训练样本，然后删除测试数据中可能缺失的某些特征。\n",
    "\n",
    "\n",
    "## 3.2 特征工程\n",
    "\n",
    "\n",
    "# 4 过拟合与欠拟合\n",
    "\n",
    "\n",
    "## 4.1 减小网络大小\n",
    "\n",
    "\n",
    "## 4.2 添加权重正则化\n",
    "\n",
    "\n",
    "## 4.3 添加 dropout 正则化\n",
    "\n",
    "\n",
    "# 5 机器学习的通用工作流程\n",
    "\n",
    "介绍一种可用于解决任何机器学习问题的通用模板：\n",
    "\n",
    "* （1）定义问题，收集数据集\n",
    "非平稳问题（nonstationary problem）\n",
    "\n",
    "* （2）选择衡量成功的指标\n",
    "    * 对于平衡分类问题（每个类别的可能性相同），精度和接收者操作特征曲线下面积（area under the receiver operating characteristic curve， ROC AUC）是常用的指标。\n",
    "    * 对于类别不平衡的问题，你可以使用准确率和召回率。\n",
    "    * 对于排序问题或多标签分类，你可以使用平均准确率均值（mean average precision）。\n",
    "\n",
    "* （3）确定评估方法\n",
    "\n",
    "一旦明确了目标，你必须确定如何衡量当前的进展。前面介绍了三种常见的评估方法。\n",
    "    * **留出验证集**。数据量很大时可以采用这种方法。\n",
    "    * **K 折交叉验证**。如果留出验证的样本量太少，无法保证可靠性，那么应该选择这种方法。\n",
    "    * **重复的 K 折验证**。如果可用的数据很少，同时模型评估又需要非常准确，那么应该使用这种方法。\n",
    "只需选择三者之一。大多数情况下，第一种方法足以满足要求。\n",
    "\n",
    "* （4）准备数据\n",
    "\n",
    "一旦知道了要训练什么、要优化什么以及评估方法，那么你就几乎已经准备好训练模型了。但首先你应该将数据格式化，使其可以输入到机器学习模型中（这里假设模型为深度神经网络）。\n",
    "    * 如前所述，应该将数据格式化为张量。\n",
    "    * 这些张量的取值通常应该缩放为较小的值，比如在 [-1, 1] 区间或 [0, 1] 区间。\n",
    "    * 如果不同的特征具有不同的取值范围（异质数据），那么应该做数据标准化。\n",
    "    * 你可能需要做特征工程，尤其是对于小数据问题。\n",
    "准备好输入数据和目标数据的张量后，你就可以开始训练模型了。\n",
    "\n",
    "* （5）开发比基准更好的模型\n",
    "\n",
    "这一阶段的目标是获得统计功效（statistical power），即开发一个小型模型，它能够打败纯随机的基准（dumb baseline）。在 MNIST 数字分类的例子中，任何精度大于 0.1 的模型都可以说具有统计功效；在 IMDB 的例子中，任何精度大于 0.5 的模型都可以说具有统计功效。注意，不一定总是能获得统计功效。如果你尝试了多种合理架构之后仍然无法打败随机基准，那么原因可能是问题的答案并不在输入数据中。要记住你所做的两个假设。\n",
    "\n",
    "    * 假设输出是可以根据输入进行预测的。\n",
    "    * 假设可用的数据包含足够多的信息，足以学习输入和输出之间的关系。\n",
    "    \n",
    "这些假设很可能是错误的，这样的话你需要从头重新开始。\n",
    "\n",
    "    * 最后一层的激活。它对网络输出进行有效的限制。例如， IMDB 分类的例子在最后一层使用了 sigmoid，回归的例子在最后一层没有使用激活，等等。\n",
    "    * 损失函数。它应该匹配你要解决的问题的类型。例如， IMDB 的例子使用 binary_crossentropy、回归的例子使用 mse， 等等。\n",
    "    * 优化配置。你要使用哪种优化器？学习率是多少？大多数情况下，使用 rmsprop 及其默认的学习率是稳妥的。\n",
    "\n",
    "关于损失函数的选择，需要注意，直接优化衡量问题成功的指标不一定总是可行的。有时难以将指标转化为损失函数，要知道损失函数需要在只有小批量数据时即可计算（理想情况下，只有一个数据点时，损失函数应该也是可计算的），而且还必须是可微的（否则无法用反向传播来训练网络）。例如，广泛使用的分类指标 ROC AUC 就不能被直接优化。因此在分类任务中，常见的做法是优化 ROC AUC 的替代指标，比如交叉熵。一般来说， 你可以认为交叉熵越小，ROC AUC 越大。\n",
    "\n",
    "![image.png](../img/04/最后一层激活和损失函数.png)\n",
    "\n",
    "* （6）扩大模型规模：开发过拟合的模型\n",
    "\n",
    "一旦得到了具有统计功效的模型，问题就变成了：模型是否足够强大？它是否具有足够多的层和参数来对问题进行建模？例如，只有单个隐藏层且只有两个单元的网络，在 MNIST 问题上具有统计功效，但并不足以很好地解决问题。请记住，机器学习中无处不在的对立是优化和泛化的对立，理想的模型是刚好在欠拟合和过拟合的界线上，在容量不足和容量过大的界线上。为了找到这条界线，你必须穿过它。要搞清楚你需要多大的模型，就必须开发一个过拟合的模型，这很简单。\n",
    "\n",
    "    * (1) 添加更多的层。\n",
    "    * (2) 让每一层变得更大。\n",
    "    * (3) 训练更多的轮次。\n",
    "\n",
    "要始终监控训练损失和验证损失，以及你所关心的指标的训练值和验证值。如果你发现模型在验证数据上的性能开始下降，那么就出现了过拟合。\n",
    "\n",
    "下一阶段将开始正则化和调节模型，以便尽可能地接近理想模型，既不过拟合也不欠拟合。\n",
    "\n",
    "* （7）模型正则化与调节超参数\n",
    "\n",
    "这一步是最费时间的：你将不断地调节模型、训练、在验证数据上评估（这里不是测试数据）、再次调节模型，然后重复这一过程，直到模型达到最佳性能。你应该尝试以下几项。\n",
    "\n",
    "    * 添加 dropout。\n",
    "    * 尝试不同的架构：增加或减少层数。\n",
    "    * 添加 L1 和 / 或 L2 正则化。\n",
    "    * 尝试不同的超参数（比如每层的单元个数或优化器的学习率），以找到最佳配置。\n",
    "    * （可选）反复做特征工程：添加新特征或删除没有信息量的特征。\n",
    "\n",
    "请注意：每次使用验证过程的反馈来调节模型，都会将有关验证过程的信息泄露到模型中。如果只重复几次，那么无关紧要；但如果系统性地迭代许多次，最终会导致模型对验证过程过拟合（即使模型并没有直接在验证数据上训练）。这会降低验证过程的可靠性。\n",
    "\n",
    "一旦开发出令人满意的模型配置，你就可以在所有可用数据（训练数据 + 验证数据）上训练最终的生产模型，然后在测试集上最后评估一次。如果测试集上的性能比验证集上差很多，那么这可能意味着你的验证流程不可靠，或者你在调节模型参数时在验证数据上出现了过拟合。在这种情况下，你可能需要换用更加可靠的评估方法，比如重复的 K 折验证。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 减小网络大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "import numpy as np\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    # Create an all-zero matrix of shape (len(sequences), dimension)\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.  # set specific indices of results[i] to 1s\n",
    "    return results\n",
    "\n",
    "# Our vectorized training data\n",
    "x_train = vectorize_sequences(train_data)\n",
    "# Our vectorized test data\n",
    "x_test = vectorize_sequences(test_data)\n",
    "# Our vectorized labels\n",
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 原始模型\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "original_model = models.Sequential()\n",
    "original_model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "original_model.add(layers.Dense(16, activation='relu'))\n",
    "original_model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "original_model.compile(optimizer='rmsprop',\n",
    "                       loss='binary_crossentropy',\n",
    "                       metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 容量更小的模型\n",
    "smaller_model = models.Sequential()\n",
    "smaller_model.add(layers.Dense(4, activation='relu', input_shape=(10000,)))\n",
    "smaller_model.add(layers.Dense(4, activation='relu'))\n",
    "smaller_model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "smaller_model.compile(optimizer='rmsprop',\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/20\n",
      "25000/25000 [==============================] - 12s 499us/step - loss: 0.4440 - acc: 0.8251 - val_loss: 0.3286 - val_acc: 0.8835\n",
      "Epoch 2/20\n",
      "25000/25000 [==============================] - 8s 330us/step - loss: 0.2573 - acc: 0.9078 - val_loss: 0.2864 - val_acc: 0.8882\n",
      "Epoch 3/20\n",
      "25000/25000 [==============================] - 8s 306us/step - loss: 0.1991 - acc: 0.9292 - val_loss: 0.2821 - val_acc: 0.8891 3s - loss: 0.1937 - ETA: 2s - loss: 0.1975 - acc: - ETA: 1s - loss: 0.1\n",
      "Epoch 4/20\n",
      "25000/25000 [==============================] - 8s 313us/step - loss: 0.1666 - acc: 0.9412 - val_loss: 0.2939 - val_acc: 0.88441628 - a\n",
      "Epoch 5/20\n",
      "25000/25000 [==============================] - 8s 319us/step - loss: 0.1435 - acc: 0.9501 - val_loss: 0.3116 - val_acc: 0.8804\n",
      "Epoch 6/20\n",
      "25000/25000 [==============================] - 8s 315us/step - loss: 0.1257 - acc: 0.9558 - val_loss: 0.3483 - val_acc: 0.8721\n",
      "Epoch 7/20\n",
      "25000/25000 [==============================] - 8s 327us/step - loss: 0.1104 - acc: 0.9615 - val_loss: 0.3598 - val_acc: 0.8722\n",
      "Epoch 8/20\n",
      "25000/25000 [==============================] - 8s 339us/step - loss: 0.0977 - acc: 0.9669 - val_loss: 0.3975 - val_acc: 0.8662\n",
      "Epoch 9/20\n",
      "25000/25000 [==============================] - 9s 346us/step - loss: 0.0841 - acc: 0.9721 - val_loss: 0.4339 - val_acc: 0.8611\n",
      "Epoch 10/20\n",
      "25000/25000 [==============================] - 10s 381us/step - loss: 0.0755 - acc: 0.9757 - val_loss: 0.4997 - val_acc: 0.8524\n",
      "Epoch 11/20\n",
      "25000/25000 [==============================] - 9s 362us/step - loss: 0.0684 - acc: 0.9778 - val_loss: 0.4872 - val_acc: 0.8587 acc:\n",
      "Epoch 12/20\n",
      "25000/25000 [==============================] - 8s 332us/step - loss: 0.0563 - acc: 0.9831 - val_loss: 0.5220 - val_acc: 0.8557\n",
      "Epoch 13/20\n",
      "25000/25000 [==============================] - 8s 319us/step - loss: 0.0513 - acc: 0.9843 - val_loss: 0.5351 - val_acc: 0.8579\n",
      "Epoch 14/20\n",
      "25000/25000 [==============================] - 9s 344us/step - loss: 0.0423 - acc: 0.9881 - val_loss: 0.6093 - val_acc: 0.8501\n",
      "Epoch 15/20\n",
      "25000/25000 [==============================] - 8s 324us/step - loss: 0.0363 - acc: 0.9894 - val_loss: 0.6115 - val_acc: 0.8558\n",
      "Epoch 16/20\n",
      "25000/25000 [==============================] - 9s 340us/step - loss: 0.0310 - acc: 0.9909 - val_loss: 0.6426 - val_acc: 0.8536\n",
      "Epoch 17/20\n",
      "25000/25000 [==============================] - 8s 332us/step - loss: 0.0265 - acc: 0.9926 - val_loss: 0.7694 - val_acc: 0.8417\n",
      "Epoch 18/20\n",
      "25000/25000 [==============================] - 8s 319us/step - loss: 0.0208 - acc: 0.9946 - val_loss: 0.7221 - val_acc: 0.8516\n",
      "Epoch 19/20\n",
      "25000/25000 [==============================] - 8s 323us/step - loss: 0.0198 - acc: 0.9949 - val_loss: 0.7739 - val_acc: 0.8476\n",
      "Epoch 20/20\n",
      "25000/25000 [==============================] - 8s 318us/step - loss: 0.0151 - acc: 0.9965 - val_loss: 0.9725 - val_acc: 0.8298\n"
     ]
    }
   ],
   "source": [
    "original_hist = original_model.fit(x_train, y_train,\n",
    "                                   epochs=20,\n",
    "                                   batch_size=512,\n",
    "                                   validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/20\n",
      "25000/25000 [==============================] - 9s 342us/step - loss: 0.5804 - acc: 0.7027 - val_loss: 0.5309 - val_acc: 0.7558\n",
      "Epoch 2/20\n",
      "25000/25000 [==============================] - 8s 321us/step - loss: 0.4843 - acc: 0.8455 - val_loss: 0.4876 - val_acc: 0.8280\n",
      "Epoch 3/20\n",
      "25000/25000 [==============================] - 8s 307us/step - loss: 0.4389 - acc: 0.8920 - val_loss: 0.4663 - val_acc: 0.8497\n",
      "Epoch 4/20\n",
      "25000/25000 [==============================] - 8s 312us/step - loss: 0.4077 - acc: 0.9154 - val_loss: 0.4526 - val_acc: 0.8663\n",
      "Epoch 5/20\n",
      "25000/25000 [==============================] - 8s 316us/step - loss: 0.3832 - acc: 0.9306 - val_loss: 0.4513 - val_acc: 0.8620\n",
      "Epoch 6/20\n",
      "25000/25000 [==============================] - 8s 324us/step - loss: 0.3620 - acc: 0.9415 - val_loss: 0.4424 - val_acc: 0.8728oss: 0.3620 - acc: 0.9\n",
      "Epoch 7/20\n",
      "25000/25000 [==============================] - 8s 312us/step - loss: 0.3425 - acc: 0.9515 - val_loss: 0.4489 - val_acc: 0.8671\n",
      "Epoch 8/20\n",
      "25000/25000 [==============================] - 8s 319us/step - loss: 0.3261 - acc: 0.9560 - val_loss: 0.4515 - val_acc: 0.8675s \n",
      "Epoch 9/20\n",
      "25000/25000 [==============================] - 8s 322us/step - loss: 0.3099 - acc: 0.9613 - val_loss: 0.4687 - val_acc: 0.8626\n",
      "Epoch 10/20\n",
      "25000/25000 [==============================] - 8s 319us/step - loss: 0.2961 - acc: 0.9649 - val_loss: 0.4632 - val_acc: 0.86492s - \n",
      "Epoch 11/20\n",
      "25000/25000 [==============================] - 8s 319us/step - loss: 0.2815 - acc: 0.9692 - val_loss: 0.4840 - val_acc: 0.8606\n",
      "Epoch 12/20\n",
      "25000/25000 [==============================] - 8s 314us/step - loss: 0.2684 - acc: 0.9718 - val_loss: 0.4873 - val_acc: 0.8626\n",
      "Epoch 13/20\n",
      "25000/25000 [==============================] - 8s 319us/step - loss: 0.2562 - acc: 0.9753 - val_loss: 0.5214 - val_acc: 0.8574\n",
      "Epoch 14/20\n",
      "25000/25000 [==============================] - 8s 324us/step - loss: 0.2454 - acc: 0.9760 - val_loss: 0.5507 - val_acc: 0.8540\n",
      "Epoch 15/20\n",
      "25000/25000 [==============================] - 8s 322us/step - loss: 0.2340 - acc: 0.9782 - val_loss: 0.5378 - val_acc: 0.8586\n",
      "Epoch 16/20\n",
      "25000/25000 [==============================] - 8s 319us/step - loss: 0.2235 - acc: 0.9802 - val_loss: 0.5300 - val_acc: 0.8582\n",
      "Epoch 17/20\n",
      "25000/25000 [==============================] - 8s 315us/step - loss: 0.2149 - acc: 0.9811 - val_loss: 0.5766 - val_acc: 0.8550loss: 0.2152 - acc: 0.98\n",
      "Epoch 18/20\n",
      "25000/25000 [==============================] - 8s 328us/step - loss: 0.2052 - acc: 0.9822 - val_loss: 0.5430 - val_acc: 0.8571\n",
      "Epoch 19/20\n",
      "25000/25000 [==============================] - 9s 348us/step - loss: 0.1965 - acc: 0.9830 - val_loss: 0.6403 - val_acc: 0.8494\n",
      "Epoch 20/20\n",
      "25000/25000 [==============================] - 8s 322us/step - loss: 0.1888 - acc: 0.9837 - val_loss: 0.7073 - val_acc: 0.8467\n"
     ]
    }
   ],
   "source": [
    "smaller_model_hist = smaller_model.fit(x_train, y_train,\n",
    "                                       epochs=20,\n",
    "                                       batch_size=512,\n",
    "                                       validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = range(1, 21)\n",
    "original_val_loss = original_hist.history['val_loss']\n",
    "smaller_model_val_loss = smaller_model_hist.history['val_loss']\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# b+ is for \"blue cross\"\n",
    "plt.plot(epochs, original_val_loss, 'b+', label='Original model')\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, smaller_model_val_loss, 'bo', label='Smaller model')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 容量更大的模型\n",
    "bigger_model = models.Sequential()\n",
    "bigger_model.add(layers.Dense(512, activation='relu', input_shape=(10000,)))\n",
    "bigger_model.add(layers.Dense(512, activation='relu'))\n",
    "bigger_model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "bigger_model.compile(optimizer='rmsprop',\n",
    "                     loss='binary_crossentropy',\n",
    "                     metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/20\n",
      "25000/25000 [==============================] - 11s 435us/step - loss: 0.4630 - acc: 0.7954 - val_loss: 0.2848 - val_acc: 0.8882\n",
      "Epoch 2/20\n",
      "25000/25000 [==============================] - 10s 407us/step - loss: 0.2237 - acc: 0.9120 - val_loss: 0.3084 - val_acc: 0.8730\n",
      "Epoch 3/20\n",
      "25000/25000 [==============================] - 10s 388us/step - loss: 0.1352 - acc: 0.9494 - val_loss: 0.3076 - val_acc: 0.8851\n",
      "Epoch 4/20\n",
      "25000/25000 [==============================] - 10s 390us/step - loss: 0.0763 - acc: 0.9792 - val_loss: 0.4175 - val_acc: 0.8808\n",
      "Epoch 5/20\n",
      "25000/25000 [==============================] - 10s 410us/step - loss: 0.0818 - acc: 0.9856 - val_loss: 0.4809 - val_acc: 0.8818\n",
      "Epoch 6/20\n",
      "25000/25000 [==============================] - 10s 387us/step - loss: 0.0728 - acc: 0.9882 - val_loss: 0.4978 - val_acc: 0.8729\n",
      "Epoch 7/20\n",
      "25000/25000 [==============================] - 10s 394us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.6401 - val_acc: 0.8789\n",
      "Epoch 8/20\n",
      "25000/25000 [==============================] - 10s 389us/step - loss: 1.9125e-04 - acc: 1.0000 - val_loss: 0.7594 - val_acc: 0.8787\n",
      "Epoch 9/20\n",
      "25000/25000 [==============================] - 10s 388us/step - loss: 0.1095 - acc: 0.9881 - val_loss: 0.7476 - val_acc: 0.8781\n",
      "Epoch 10/20\n",
      "25000/25000 [==============================] - 10s 384us/step - loss: 5.5737e-04 - acc: 1.0000 - val_loss: 0.7769 - val_acc: 0.8779\n",
      "Epoch 11/20\n",
      "25000/25000 [==============================] - 10s 386us/step - loss: 2.0219e-05 - acc: 1.0000 - val_loss: 0.8623 - val_acc: 0.8781\n",
      "Epoch 12/20\n",
      "25000/25000 [==============================] - 10s 385us/step - loss: 3.3496e-06 - acc: 1.0000 - val_loss: 0.9439 - val_acc: 0.8774\n",
      "Epoch 13/20\n",
      "25000/25000 [==============================] - 10s 391us/step - loss: 5.9520e-07 - acc: 1.0000 - val_loss: 1.0177 - val_acc: 0.8777\n",
      "Epoch 14/20\n",
      "25000/25000 [==============================] - 10s 395us/step - loss: 1.8911e-07 - acc: 1.0000 - val_loss: 1.0676 - val_acc: 0.8779\n",
      "Epoch 15/20\n",
      "25000/25000 [==============================] - 10s 384us/step - loss: 1.2898e-07 - acc: 1.0000 - val_loss: 1.0911 - val_acc: 0.8780\n",
      "Epoch 16/20\n",
      "25000/25000 [==============================] - 10s 387us/step - loss: 1.1806e-07 - acc: 1.0000 - val_loss: 1.1053 - val_acc: 0.8781\n",
      "Epoch 17/20\n",
      "25000/25000 [==============================] - 10s 395us/step - loss: 1.1434e-07 - acc: 1.0000 - val_loss: 1.1139 - val_acc: 0.8780\n",
      "Epoch 18/20\n",
      "25000/25000 [==============================] - 10s 391us/step - loss: 1.1264e-07 - acc: 1.0000 - val_loss: 1.1191 - val_acc: 0.8778\n",
      "Epoch 19/20\n",
      "25000/25000 [==============================] - 10s 389us/step - loss: 1.1174e-07 - acc: 1.0000 - val_loss: 1.1231 - val_acc: 0.8778\n",
      "Epoch 20/20\n",
      "25000/25000 [==============================] - 10s 389us/step - loss: 1.1123e-07 - acc: 1.0000 - val_loss: 1.1267 - val_acc: 0.8778\n"
     ]
    }
   ],
   "source": [
    "bigger_model_hist = bigger_model.fit(x_train, y_train,\n",
    "                                     epochs=20,\n",
    "                                     batch_size=512,\n",
    "                                     validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bigger_model_val_loss = bigger_model_hist.history['val_loss']\n",
    "\n",
    "plt.plot(epochs, original_val_loss, 'b+', label='Original model')\n",
    "plt.plot(epochs, bigger_model_val_loss, 'bo', label='Bigger model')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "original_train_loss = original_hist.history['loss']\n",
    "bigger_model_train_loss = bigger_model_hist.history['loss']\n",
    "\n",
    "plt.plot(epochs, original_train_loss, 'b+', label='Original model')\n",
    "plt.plot(epochs, bigger_model_train_loss, 'bo', label='Bigger model')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Training loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 添加权重正则化\n",
    "\n",
    "奥卡姆剃刀（Occam’s razor）原理：如果一件事情有两种解释，那么最可能正确的解释就是最简单的那个，即假设更少的那个。这个原理也适用于神经网络学到的模型：给定一些训练数据和一种网络架构，很多组权重值（即很多模型）都可以解释这些数据。简单模型比复杂模型更不容易过拟合。\n",
    "\n",
    "这里的简单模型（simple model）是指参数值分布的熵更小的模型（或参数更少的模型，比如上一节的例子）。因此，一种常见的降低过拟合的方法就是强制让模型权重只能取较小的值，从而限制模型的复杂度，这使得权重值的分布更加规（regular）。这种方法叫作权重正则化（weight regularization），其实现方法是向网络损失函数中添加与较大权重值相关的成（cost）。\n",
    "\n",
    "这个成本有两种形式。\n",
    "\n",
    "* L1 正则化（L1 regularization）：添加的成本与权重系数的绝对值［权重的 L1 范数（norm）］成正比。\n",
    "* L2 正则化（L2 regularization）：添加的成本与权重系数的平方（权重的 L2 范数）成正比。神经网络的 L2 正则化也叫权重衰减（weight decay）。不要被不同的名称搞混，权重衰减与 L2 正则化在数学上是完全相同的。\n",
    "\n",
    "在 Keras 中，添加权重正则化的方法是向层传递权重正则化项实例（weight regularizer instance）作为关键字参数。下列代码将向电影评论分类网络中添加 L2 权重正则化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 向模型添加 L2 权重正则化\n",
    "from keras import regularizers\n",
    "\n",
    "l2_model = models.Sequential()\n",
    "l2_model.add(layers.Dense(16, \n",
    "                          kernel_regularizer=regularizers.l2(0.001),\n",
    "                          activation='relu', \n",
    "                          input_shape=(10000,)))\n",
    "l2_model.add(layers.Dense(16, \n",
    "                          kernel_regularizer=regularizers.l2(0.001),\n",
    "                          activation='relu'))\n",
    "l2_model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "l2_model.compile(optimizer='rmsprop',\n",
    "                 loss='binary_crossentropy',\n",
    "                 metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/20\n",
      "25000/25000 [==============================] - 9s 367us/step - loss: 0.4879 - acc: 0.8152 - val_loss: 0.3895 - val_acc: 0.8656\n",
      "Epoch 2/20\n",
      "25000/25000 [==============================] - 8s 316us/step - loss: 0.3100 - acc: 0.9061 - val_loss: 0.3306 - val_acc: 0.8891\n",
      "Epoch 3/20\n",
      "25000/25000 [==============================] - 8s 315us/step - loss: 0.2657 - acc: 0.9202 - val_loss: 0.3301 - val_acc: 0.8872: 3s - loss: 0.2621 - - ETA: \n",
      "Epoch 4/20\n",
      "25000/25000 [==============================] - 8s 316us/step - loss: 0.2459 - acc: 0.9286 - val_loss: 0.3413 - val_acc: 0.8821\n",
      "Epoch 5/20\n",
      "25000/25000 [==============================] - 8s 317us/step - loss: 0.2323 - acc: 0.9352 - val_loss: 0.3818 - val_acc: 0.8685\n",
      "Epoch 6/20\n",
      "25000/25000 [==============================] - 8s 318us/step - loss: 0.2237 - acc: 0.9390 - val_loss: 0.3676 - val_acc: 0.8752 - loss: 0.2234 - acc: 0.939\n",
      "Epoch 7/20\n",
      "25000/25000 [==============================] - 8s 318us/step - loss: 0.2173 - acc: 0.9409 - val_loss: 0.3748 - val_acc: 0.8735\n",
      "Epoch 8/20\n",
      "25000/25000 [==============================] - 8s 317us/step - loss: 0.2106 - acc: 0.9445 - val_loss: 0.3726 - val_acc: 0.8752\n",
      "Epoch 9/20\n",
      "25000/25000 [==============================] - 8s 318us/step - loss: 0.2045 - acc: 0.9466 - val_loss: 0.3762 - val_acc: 0.8753 loss: 0.1960  - ETA: 0s - loss: 0.2016 - acc: \n",
      "Epoch 10/20\n",
      "25000/25000 [==============================] - 8s 320us/step - loss: 0.2009 - acc: 0.9500 - val_loss: 0.3822 - val_acc: 0.8748\n",
      "Epoch 11/20\n",
      "25000/25000 [==============================] - 8s 316us/step - loss: 0.1950 - acc: 0.9495 - val_loss: 0.3838 - val_acc: 0.8755\n",
      "Epoch 12/20\n",
      "25000/25000 [==============================] - 8s 315us/step - loss: 0.1922 - acc: 0.9518 - val_loss: 0.3918 - val_acc: 0.8745\n",
      "Epoch 13/20\n",
      "25000/25000 [==============================] - 8s 320us/step - loss: 0.1876 - acc: 0.9548 - val_loss: 0.3972 - val_acc: 0.8734\n",
      "Epoch 14/20\n",
      "25000/25000 [==============================] - 8s 334us/step - loss: 0.1820 - acc: 0.9567 - val_loss: 0.4331 - val_acc: 0.8642\n",
      "Epoch 15/20\n",
      "25000/25000 [==============================] - 8s 330us/step - loss: 0.1816 - acc: 0.9574 - val_loss: 0.4568 - val_acc: 0.8566\n",
      "Epoch 16/20\n",
      "25000/25000 [==============================] - 8s 309us/step - loss: 0.1757 - acc: 0.9596 - val_loss: 0.4463 - val_acc: 0.8643: 3s - loss: 0.1436 - a - ETA:\n",
      "Epoch 17/20\n",
      "25000/25000 [==============================] - 8s 311us/step - loss: 0.1717 - acc: 0.9613 - val_loss: 0.4222 - val_acc: 0.8696 loss: 0.1708 - acc:\n",
      "Epoch 18/20\n",
      "25000/25000 [==============================] - 8s 319us/step - loss: 0.1665 - acc: 0.9637 - val_loss: 0.4374 - val_acc: 0.8672\n",
      "Epoch 19/20\n",
      "25000/25000 [==============================] - 8s 319us/step - loss: 0.1648 - acc: 0.9642 - val_loss: 0.4623 - val_acc: 0.8594\n",
      "Epoch 20/20\n",
      "25000/25000 [==============================] - 8s 323us/step - loss: 0.1616 - acc: 0.9667 - val_loss: 0.4412 - val_acc: 0.8665\n"
     ]
    }
   ],
   "source": [
    "l2_model_hist = l2_model.fit(x_train, y_train,\n",
    "                             epochs=20,\n",
    "                             batch_size=512,\n",
    "                             validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3XucFPWZ7/HPw4gZUbxFYlAugxw03AaQATQXEG+oUfCuLGdPwETiBUXNMRoxMprjGj2J7nqJiReCrkRUjEoSNjGKwtElWQblqstFF3QWVgcMIo6sAz7nj6ppmqF7ume6q6tn+vt+veo1XdW/qnq6KOqp+tWvfmXujoiICECHuAMQEZHioaQgIiIJSgoiIpKgpCAiIglKCiIikqCkICIiCUoKIiKSoKQgIiIJkSUFM5thZh+a2co035uZ3Wtm68xsuZkdG1UsIiKSnX0iXPZM4H7g8TTfnw70CYcRwIPh32YddthhXlFRkZ8IRURKxJIlSza7e5dM5SJLCu6+0MwqmikyDnjcg342/mJmB5tZV3ff1NxyKyoqqKmpyWOkIiLtn5ltyKZcnPcUjgTeTxqvDaftxcwmm1mNmdXU1dUVJDgRkVIUZ1KwFNNS9s7n7g+5e5W7V3XpkvHqR0REWinOpFALdE8a7wZsjCkWEREh2hvNmcwFppjZbIIbzB9nup+QTkNDA7W1tezYsSOvAUr7VV5eTrdu3ejYsWPcoYgUlciSgpk9CZwAHGZmtcB0oCOAu/8SmAecAawD6oFJrV1XbW0tnTt3pqKiArNUtVIiu7k7W7Zsoba2ll69esUdjkhRibL10fgM3ztwZT7WtWPHDiUEyZqZ8eUvfxk1WpC2pro6GKLUbp5oVkKQltD+Im3RrbdGv452kxRERCR3Sgp5Ultby7hx4+jTpw+9e/dm6tSpfP755ynLbty4kfPPPz/jMs844wy2bt3aqniqq6v52c9+1qp5szVz5kymTJmScxkRSa+6GsyCAXZ/jqoaqaSTQr42qrtz7rnncvbZZ7N27VrWrFnD9u3bmTZt2l5ld+7cyRFHHMGcOXMyLnfevHkcfPDB+QlSRNqk6mpwDwbY/VlJIQL5qp+bP38+5eXlTJoUNKAqKyvjnnvuYcaMGdTX1zNz5kwuuOACzjrrLE499VTWr1/PgAEDAKivr+fCCy+ksrKSiy66iBEjRiS68aioqGDz5s2sX7+evn37cumll9K/f39OPfVUPvvsMwAefvhhhg0bxqBBgzjvvPOor69vNtaJEydy+eWXM3r0aI466igWLFjAJZdcQt++fZk4cWKi3JNPPsnAgQMZMGAAN9xwQ2L6r3/9a44++mhGjRrF66+/npheV1fHeeedx7Bhwxg2bNge34lI21HSSSFfVq1axdChQ/eYduCBB9KjRw/WrVsHwKJFi3jssceYP3/+HuV+8YtfcMghh7B8+XJ+/OMfs2TJkpTrWLt2LVdeeSWrVq3i4IMP5tlnnwXg3HPPZfHixSxbtoy+ffvy6KOPZoz3b3/7G/Pnz+eee+7hrLPO4tprr2XVqlWsWLGCpUuXsnHjRm644Qbmz5/P0qVLWbx4Mc8//zybNm1i+vTpvP766/z5z3/mrbfeSixz6tSpXHvttSxevJhnn32W733vey3ahiKS2fTp0a8jzofXYlFdvecVQmM93fTprb8cc/eUrVmSp59yyikceuihe5V57bXXmDp1KgADBgygsrIy5Tp69erF4MGDARg6dCjr168HYOXKldx8881s3bqV7du3M2bMmIzxnnXWWZgZAwcO5PDDD2fgwIEA9O/fn/Xr17NhwwZOOOEEGrsUmTBhAgsXLgTYY/pFF13EmjVrAHjppZf2SBLbtm3jk08+yRiLiGQv6uaoUKJJoXHDmu2up8tF//79E2fujbZt28b7779P7969WbJkCfvvv3/KeT3LAL70pS8lPpeVlSWqjyZOnMjzzz/PoEGDmDlzJq+++mrWy+rQocMey+3QoQM7d+5kn33S7xbpmnJ+8cUXLFq0iP322y+bnyMiRUrVR3lw0kknUV9fz+OPB6+O2LVrFz/4wQ+YOHEinTp1anbeb37zmzz99NMAvPXWW6xYsaJF6/7kk0/o2rUrDQ0NzJo1q3U/oIkRI0awYMECNm/ezK5du3jyyScZNWoUI0aM4NVXX2XLli00NDTwzDPPJOY59dRTuf/++xPjS5cuzUssIlJYJZ0U8lU/Z2Y899xzPPPMM/Tp04ejjz6a8vJy/uEf/iHjvFdccQV1dXVUVlZy5513UllZyUEHHZT1un/yk58wYsQITjnlFL72ta/l8jMSunbtyh133MHo0aMZNGgQxx57LOPGjaNr165UV1dz/PHHc/LJJ3PssbtflnfvvfdSU1NDZWUl/fr145e//GVeYhGRwrJsqy+KRVVVlTd9yc7bb79N3759Y4ooN7t27aKhoYHy8nLeeecdTjrpJNasWcO+++4bd2jtXlveb0RaysyWuHtVpnIld0+h2NTX1zN69GgaGhpwdx588EElBBGJjZJCzDp37qzXi4pI0SjpewoiIrInJQUREUlQUhARkQQlBRERSVBSyJMDDjhgr2l33303/fr1o7KykpNOOokNGzYUPK7WdKE9d+5cfvrTn+a87hNOOCHym+gTJ07M2ONsNmVEJFCSSWHWLKiogA4dgr95ehB4L0OGDKGmpobly5dz/vnn88Mf/jDjPDt37owmmCzt3LmTsWPHcuONN8Yah4jEI9KkYGanmdlqM1tnZnsdZcysp5m9bGbLzexVM+sWZTwQJIDJk2HDhqDfow0bgvEoEsPo0aMT3Vwcd9xx1NbWpiw3ceJErrvuOkaPHs0NN9zAp59+yiWXXMKwYcMYMmQIL7zwAtB8N9vJVypz5szZoxvsRum62W66/uQX4wwePDgx7LfffixYsCBtfJ999hkXX3xxIr7G/pmaqqio4KabbuL444+nqqqKN954gzFjxtC7d+/Ek9DuzvXXX8+AAQMYOHAgTz31VGL6lClT6NevH9/+9rf58MMPE8tdsmQJo0aNYujQoYwZM4ZNmzZl9w8lIgmRPadgZmXAA8ApQC2w2MzmuvtbScV+Bjzu7o+Z2YnAHcDfRxUTwLRp0PSVA/X1wfQJE6Jb76OPPsrpp5+e9vs1a9bw0ksvUVZWxk033cSJJ57IjBkz2Lp1K8OHD+fkk0/mwQcfTHSzvXLlykSvqdk699xzufTSSwG4+eabefTRR7nqqqv2Wv/MmTMT8zT2YfS73/2Ou+66i69//etMnz49ZXy/+tWv6NSpE8uXL2f58uV7dIPRVPfu3Vm0aBHXXnstEydO5PXXX2fHjh3079+fyy67jN/+9rcsXbqUZcuWsXnzZoYNG8bIkSNZtGgRq1evZsWKFXzwwQf069ePSy65hIaGBq666ipeeOEFunTpwlNPPcW0adOYMWNGi7aRSKmL8uG14cA6d38XwMxmA+OA5KTQD7g2/PwK8HyE8QDw3nstm54PTzzxBDU1NSxYsCBtmQsuuICysjIAXnzxRebOnZu4F7Bjxw7ee++9rLvZTqe5braT19/U2rVruf7665k/fz4dO3ZMG9/ChQu5+uqrAaisrGw2vrFjxwIwcOBAtm/fTufOnencuTPl5eVs3bqV1157jfHjx1NWVsbhhx/OqFGjWLx4MQsXLkxMP+KIIzjxxBMBWL16NStXruSUU04Bgu5Dunbt2qLtIyLRJoUjgfeTxmuBEU3KLAPOA/4JOAfobGZfdvctUQXVo0dQZZRqehReeuklbr/9dhYsWJDopnratGn84Q9/AHafiSd3re3uPPvssxxzzDF7LKu5fqqSu7TesWNHyjLNdbOdrmvvTz/9lAsvvJCHH36YI444otn4msbRnEzdd2f7Wxu5O/3792fRokVZrV9EUovynkKqo0PT/+n/GxhlZm8Co4D/BPa602pmk82sxsxq6urqcgrq9tuhaW/WnToF0/PtzTff5Pvf/z5z587lK1/5SlIMt7N06dK03UuPGTOG++67L3FgfPPNN4Hmu9k+/PDDefvtt/niiy947rnnUi63Nd1sT5o0iUmTJvGtb30rY3wjR45MLHflypUsX748q3WkMnLkSJ566il27dpFXV0dCxcuZPjw4YwcOZLZs2eza9cuNm3axCuvvALAMcccQ11dXSIpNDQ0sGrVqlavX6RURXmlUAt0TxrvBmxMLuDuG4FzAczsAOA8d/+46YLc/SHgIQh6Sc0lqMb7BtOmBVVGPXoECSHX+wn19fV067b7Pvl1113HvHnz2L59OxdccAEAPXr0YO7cuRmX9eMf/5hrrrmGyspK3J2Kigp+//vfc8UVV/Cd73yHyspKhgwZskc32z/96U8588wz6d69OwMGDGD79u17Lbexm+2ePXsycODAjG9G27BhA3PmzGHNmjWJuvlHHnkkbXyXX345kyZNorKyksGDBzN8+PCst19T55xzDosWLWLQoEGYGXfddRdf/epXOeecc5g/fz4DBw5MvCsaYN9992XOnDlcffXVfPzxx+zcuZNrrrmG/v37tzoGkVIUWdfZZrYPsAY4ieAKYDHwd+6+KqnMYcBH7v6Fmd0O7HL3W5pbbnvrOrsl1M12fpXKfiMCRdB1trvvNLMpwJ+AMmCGu68ys9uAGnefC5wA3GFmDiwErowqnvZA3WyLSNQi7Trb3ecB85pMuyXp8xxAj5pmSd1si0jU2s0TzW3tDXISL+0vIqm1i6RQXl7Oli1b9B9dsuLubNmyhfLy8rhDESk67eLNa926daO2tpZcm6tK6SgvL9+jtZiIBNpFUujYsSO9evWKOwwRkTavXVQfiYhIfigpiIhIgpKCiIgkKCmIiEiCkoKIiCQoKYiISIKSgoiIJCgpiIhIgpKCiIgkKCmIiEiCkoKIiCQoKYiISIKSgoiIJCgpiIhIgpKCiIgkKCmIiEhCpEnBzE4zs9Vmts7MbkzxfQ8ze8XM3jSz5WZ2RpTxiIhI8yJLCmZWBjwAnA70A8abWb8mxW4Gnnb3IcDFwC+iikdERDKL8kphOLDO3d9198+B2cC4JmUcODD8fBCwMcJ4REQkgyjf0Xwk8H7SeC0wokmZauBFM7sK2B84OcJ4REQkgyivFCzFNG8yPh6Y6e7dgDOAfzazvWIys8lmVmNmNXV1dRGEKiIiEG1SqAW6J413Y+/qoe8CTwO4+yKgHDis6YLc/SF3r3L3qi5dukQUroiIRJkUFgN9zKyXme1LcCN5bpMy7wEnAZhZX4KkoEsBEZGYRJYU3H0nMAX4E/A2QSujVWZ2m5mNDYv9ALjUzJYBTwIT3b1pFZOIiBRIlDeacfd5wLwm025J+vwW8I0oYxARKRbV1cFQzPREs4iUjLgPyLfeGu/6s6GkICIloy0clOOmpCAiEqHqajALBtj9Oe6rlnSUFESkXYv7oFxdDe7BALs/F2tSsLbW2KeqqspramriDkNE2iCz3QfnUlu/mS1x96pM5XSlICJSINOnxx1BZkoKIlIy4j4oF2uVUTIlBREpGW3hoBw3JQUREUnImBTMbP/GnkvN7GgzG2tmHaMPTURECi2bK4WFQLmZHQm8DEwCZkYZlIiIxCObpGDuXg+cC9zn7ucQvF5TRETamaySgpkdD0wA/hBOi7QjPRERiUc2SeEa4EfAc2HX10cBr0QbloiIxCFjUnD3Be4+1t3vDG84b3b3qwsQm4hIUSmFJq3ZtD76jZkdaGb7A28Bq83s+uhDExEpLqXQy2o21Uf93H0bcDbBC3N6AH8faVQiIhKLbJJCx/C5hLOBF9y9AWhbveiJiLRS3L2sFlo2SeFXwHpgf2ChmfUEtkUZlIhIsWhrXV/nKmPTUne/F7g3adIGMxsdXUgiIhKXbG40H2Rmd5tZTTj8nOCqISMzO83MVpvZOjO7McX395jZ0nBYY2ZbW/EbREQKIu5eVgshm+qjGcAnwIXhsA34daaZzKwMeAA4neAJ6PFmtseT0O5+rbsPdvfBwH3Ab1sWvohI4bTXKqNk2TyZ3Nvdz0sav9XMlmYx33Bgnbu/C2Bms4FxBM1aUxkPlEAeFhEpXtlcKXxmZt9sHDGzbwCfZTHfkcD7SeO14bS9hDevewHz03w/ubH6qq6uLotVi4hIa2RzpXA58JiZHQQY8BEwMYv5LMW0dE1ZLwbmuPuuVF+6+0PAQxC8ozmLdYuISCtk0/poKTDIzA4Mx7NtjloLdE8a7wZsTFP2YuDKLJcrIiIRSZsUzOy6NNMBcPe7Myx7MdDHzHoB/0lw4P+7FMs7BjgEWJRdyCIiEpXmrhQ657Jgd99pZlOAPwFlwIywl9XbgBp3nxsWHQ/MdndVC4mIxMza2rG4qqrKa2pq4g5DRKRNMbMl7l6VqVw2rY9ERKREKCmIiEiCkoKIiCRkbJJqZl8CzgMqksu7+23RhSUiInHI5uG1F4CPgSXAf0cbjoiIxCmbpNDN3U+LPBIREYldNvcU/tXMBkYeiYiIxC6bK4VvAhPN7D8Iqo8McHevjDQyEREpuGySwumRRyEikoXq6tJ4p0GcMlYfufsG4GDgrHA4OJwmIlJQt94adwTtXzav45wKzAK+Eg5PmNlVUQcmIiKFl82N5u8CI9z9Fne/BTgOuDTasEREAtXVYBYMsPuzqpGikc09BQOSX36zi9Qv0BERybvk+whm0Mb68GxzskkKvwb+ambPheNnA49GF5KIiMQlmzev3W1mrxI0TTVgkru/GXVgIiJNTZ8edwTtX3NvXjvQ3beZ2aHA+nBo/O5Qd/8o+vBERHbTfYToNXel8BvgTII+j5Jr8SwcPyrCuEREJAZpWx+5+5nh317uflTS0MvdlRBESlCuZ+o60y9+2Tyn8HI200Sk/cv14TE9fFb80iYFMysP7yccZmaHmNmh4VABHJHNws3sNDNbbWbrzOzGNGUuNLO3zGyVmf2mNT9CRETyo7krhe8T3E/4Wvi3cXgBeCDTgs2sLCx3OtAPGG9m/ZqU6QP8CPiGu/cHrmnFbxCRCOX68JgePmtbzDM8CWJmV7n7fS1esNnxQLW7jwnHfwTg7ncklbkLWOPuj2S73KqqKq+pqWlpOCKSB7k+PKaHz+JjZkvcvSpTuWyeU7jPzAYQnO2XJ01/PMOsRwLvJ43XAiOalDk6DPZ1oIwgifwxU0wiIhKNbN7RPB04gSApzCOoDnoNyJQUUnWF0fQcYR+gT7j8bsD/M7MB7r61SQyTgckAPXr0yBSyiEQk14fH9PBZ8cumQ7zzgZOA/3L3ScAg4EtZzFcLdE8a7wZsTFHmBXdvcPf/AFYTJIk9uPtD7l7l7lVdunTJYtUiEgU1SW3/skkKn7n7F8BOMzsQ+JDsHlxbDPQxs15mti9wMTC3SZnngdEAZnYYQXXSu9kGLyIi+ZVNh3g1ZnYw8DBB66PtwL9lmsndd5rZFOBPBPcLZrj7KjO7Dahx97nhd6ea2VsEva9e7+5bWvlbREQkRxlbH+1ROHhG4UB3Xx5VQJmo9ZGISMvl3PrIzI5t7jt3f6O1wYmISHFqrvro5+HfcqAKWEbQoqgS+CtBV9oiItKONNch3mh3Hw1sAI4NW/8MBYYA6woVoIiIFE42rY++5u4rGkfcfSUwOLqQREQkLtm0PnrbzB4BniB4+Ox/Am9HGpWIiMQim6QwCbgcmBqOLwQejCwiERGJTTZ9H+0A7gkHERFpx5prkvq0u19oZivYu88i3L0y0shERKTgmrtSaKwuOrMQgYiISPzSJgV33xT+3VC4cEREJE7NvY7zEzPblmL4xMy2FTJIEckP9VIqmTT38Fpndz8wxdDZ3Q8sZJAikh+33hp3BFLssmmSCoCZfYU937z2XiQRiYhIbDI+0WxmY81sLfAfwAJgPfAvEcclInlSXR28G9nCdyE2flZVkqSSTTcXPwGOA9a4ey+Ct7C9HmlUIpJSaw7k1dXgHgyw+7OSgqSSTVJoCF9808HMOrj7K6jvI5FY6J6ARC2bewpbzewAgu4tZpnZh8DOaMMSkShMnx53BFLssrlSGAd8BlwL/BF4BzgryqBEZLd83hNQlZFkkvZ1nGZ2P/Abd//XwobUPL2OU0qZ2e57AyItke3rOJu7UlgL/NzM1pvZnWam+wgiIu1ccw+v/ZO7Hw+MAj4Cfm1mb5vZLWZ2dDYLN7PTzGy1ma0zsxtTfD/RzOrMbGk4fK/Vv0SkBOiegEQt4z0Fd9/g7ne6+xDg74BzyOIlO2ZWBjwAnA70A8abWb8URZ9y98Hh8EjLwhcpnGKojy+GGKR9y+bhtY5mdpaZzSJ4aG0NcF4Wyx4OrHP3d939c2A2wU1rkTZJzUGlFDTXId4pZjYDqAUmA/OA3u5+kbs/n8WyjwTeTxqvDac1dZ6ZLTezOWbWvQWxi4hInjV3pXATsAjo6+5nufssd/+0Bcu2FNOatpv4HVARvrDnJeCxlAsym2xmNWZWU1dX14IQRHKj5qBSatI2Sc15wWbHA9XuPiYc/xGAu9+RpnwZ8JG7H9TcctUkVeKSa3NQNSeVOOWjSWquFgN9zKyXme0LXAzMTS5gZl2TRseSxQ1sERGJTmRJwd13AlOAPxEc7J9291VmdpuZjQ2LXW1mq8xsGXA1MDGqeERy1ZrmoOqhVNqayKqPoqLqI2mrVH0kcSqG6iMREWljlBRECkRPI0tboKQgUiC6j1C6Zs2Cigro0CH4O2tW3BGll/U7mkVEpOVmzYLJk6G+PhjfsCEYB5gwIb640tGVgohEri2dKefbtGm7E0Kj+vpgejHSlYKIRKqtnSnn23vvtWx63HSlICKRamtnyvnWo0fLpsdNSUFEIpWPM+W2XP10++3QqdOe0zp1CqYXIyUFEYlUrmfKjdVPGzYED/81Vj+1lcQwYQI89BD07Bk8wNizZzDekqqzQiZFJQURiVSuZ8rFUP2U60F5wgRYvx6++CL429KEUMikqKQgJUPPCcQj1zPluG/Uxn2lUuikqL6PpGSo76HWmzUrOAi9915Q7XP77YVrOVRRERyIm+rZMzjrbu/r79Ah9X5rFlx5ZEt9H4lIXsR9phz3jdq4r1QK3XpJSUHaNXVdnbu46/TzcaM2F3E3KS14UnT3NjUMHTrURVoD4o6gbTILtl3TwSzuyLL3xBPuPXsGMffsGYy3ZN5Onfb87Z06tWwZucol/kZAjWdxjNUTzSLSrB49UtepF+vDV03l+kR1Y5m47qk0xlCo9an6SEqGuq5unbjr9HOVj+qvXJqUtjVKClIydB+hdeKu089V3DeK2xpVH4lIRoWsvsi3tl79VWiRXimY2WlmttrM1pnZjc2UO9/M3MwytqEVEWmJtl79VWiRJQUzKwMeAE4H+gHjzaxfinKdgauBv0YVi4iUrrZe/VVoUV4pDAfWufu77v45MBsYl6LcT4C7gB0RxiLtgO4JtF5b7mU0H0rpRnGuokwKRwLvJ43XhtMSzGwI0N3dfx9hHNJO3Hpr3BG0TXE/kSxtS5RJwVJMS/TgYWYdgHuAH2RckNlkM6sxs5q6uroWB1LqZ0nS9uWyD8f9RLK0LVEmhVqge9J4N2Bj0nhnYADwqpmtB44D5qa62ezuD7l7lbtXdenSpUVB6CypbVM3Fbnvw2qSKS2SzWPPrRkImru+C/QC9gWWAf2bKf8qUJVpuS3t5qJnz9SP6Pfs2aLFtGn5eES+GMTVTUWu2y/X+XPdh/V/QNyz7+Yi0n6KgDOANcA7wLRw2m3A2BRlI0kK7aHfllwUQ78t+RJHUsh1++Vj++e6D7enfUBaryiSQhSDrhRaphh+f76uVKZPL/z6i+EsPR/LaC9Xi9J6SgqhUj9LivtKKR/bP84eLnPdfvnY/qW+D0t+KCkkKeWzpLjPMnNdf64HxLjP9PN1pVbK+7Dkh5KCuHv8deK5ninnelCNuz5eZ/lSLJQUJKEt16nHnVTc4299JJIP2SYFC8q2HVVVVV5TUxN3GCUj15eGN33BCQSdkWXb90yuL03Pdf0i7YWZLXH3jJ2O6n0K0qxc30+b3BkZtLwzslx7uFRnaCItoysFaVY+z7TNUl91ZBNDnK9CFGkPdKUgeZHrmX4+uqlQD5cihaMrBclaa8/08zW/iLSerhTaEfXyKiKFoqRQ5OLu5TWfvZROn57PyEQkCqo+KnK5NsnMJ1X/iLRdqj7Ko1yrb3KZX33hi0ghlVRSaE2VR67VN7nOn+tzAvmk6h+R9q+kqo9aU/2Ra/WNnsgVkWKg6qM8ybX6Jtf59USuiBRSu08KubaeybX6Jh/VP3p4S0QKpSSSQmPfmLD7c7ZJIde+d3KdP59K6WX3ItI67T4p5CrX6ptiqv659dbCr1NE2paSutFcXV3aZ8t6zkCkdBXFjWYzO83MVpvZOjO7McX3l5nZCjNbamavmVm/KOMpxYSQzyeSRaT9i+xKwczKgDXAKUAtsBgY7+5vJZU50N23hZ/HAle4+2nNLbfUnmjOJ10piJSuYrhSGA6sc/d33f1zYDYwLrlAY0II7Q/okCUiEqMok8KRwPtJ47XhtD2Y2ZVm9g5wF3B1hPG0eblW+eiJZBHJJMqkYCmm7XUl4O4PuHtv4Abg5pQLMptsZjVmVlNXV5fnMNuOXFsP6T6CiGQSZVKoBbonjXcDNjZTfjZwdqov3P0hd69y96ouXbrkMcSW0UFVRNq7KJPCYqCPmfUys32Bi4G5yQXMrE/S6LeBtRHGk7M4ztTVekhECinS5xTM7AzgH4EyYIa7325mtwE17j7XzP4JOBloAP4GTHH3Vc0tM87WR3G/jlKth0SktYqh9RHuPs/dj3b33u5+ezjtFnefG36e6u793X2wu4/OlBDioDN1ESkl6uYig1z7TtLrLEWkLSmpbi5ypeofEWmriqL6qL3RmbqItHdKCi2gh8dEpL1TUigg3ZwWkWKnpCAiIglKCiIikqCkICIiCUoKIiKSoKQgIiIJbe7hNTOrAzbEHUcahwGb4w6iGYovN8UeHxR/jIovN7nE19PdM3Yz3eaSQjEzs5psnhiMi+LLTbHHB8Ufo+LLTSHiU/WRiIgkKCmIiEiCkkJ+PRR3ABkovtwUe3xQ/DEqvtxEHp+fsJ12AAAGKElEQVTuKYiISIKuFEREJEFJoYXMrLuZvWJmb5vZKjObmqLMCWb2sZktDYdbChzjejNbEa57r5dPWOBeM1tnZsvN7NgCxnZM0nZZambbzOyaJmUKvv3MbIaZfWhmK5OmHWpmfzazteHfQ9LM+52wzFoz+06BYvu/Zvbv4b/fc2Z2cJp5m90XIo6x2sz+M+nf8Yw0855mZqvD/fHGAsb3VFJs681saZp5I92G6Y4pse1/7q6hBQPQFTg2/NwZWAP0a1LmBOD3Mca4Hjisme/PAP4FMOA44K8xxVkG/BdB++lYtx8wEjgWWJk07S7gxvDzjcCdKeY7FHg3/HtI+PmQAsR2KrBP+PnOVLFlsy9EHGM18L+z2AfeAY4C9gWWNf3/FFV8Tb7/OXBLHNsw3TElrv1PVwot5O6b3P2N8PMnwNvAkfFG1WLjgMc98BfgYDPrGkMcJwHvuHvsDyO6+0LgoyaTxwGPhZ8fA85OMesY4M/u/pG7/w34M3Ba1LG5+4vuvjMc/QvQLZ/rbKk02y8bw4F17v6uu38OzCbY7nnVXHxmZsCFwJP5Xm82mjmmxLL/KSnkwMwqgCHAX1N8fbyZLTOzfzGz/gUNDBx40cyWmNnkFN8fCbyfNF5LPIntYtL/R4xz+zU63N03QfAfF/hKijLFsC0vIbjySyXTvhC1KWEV14w01R/FsP2+BXzg7mvTfF+wbdjkmBLL/qek0EpmdgDwLHCNu29r8vUbBFUig4D7gOcLHN433P1Y4HTgSjMb2eR7SzFPQZuhmdm+wFjgmRRfx739WiLWbWlm04CdwKw0RTLtC1F6EOgNDAY2EVTRNBX7vgiMp/mrhIJswwzHlLSzpZiW0/ZTUmgFM+tI8I83y91/2/R7d9/m7tvDz/OAjmZ2WKHic/eN4d8PgecILtGT1QLdk8a7ARsLE13C6cAb7v5B0y/i3n5JPmisVgv/fpiiTGzbMrypeCYwwcMK5qay2Bci4+4fuPsud/8CeDjNumPdF81sH+Bc4Kl0ZQqxDdMcU2LZ/5QUWiisf3wUeNvd705T5qthOcxsOMF23lKg+PY3s86NnwluSK5sUmwu8L/CVkjHAR83XqYWUNqzszi3XxNzgcbWHN8BXkhR5k/AqWZ2SFg9cmo4LVJmdhpwAzDW3evTlMlmX4gyxuT7VOekWfdioI+Z9QqvHi8m2O6FcjLw7+5em+rLQmzDZo4p8ex/Ud1Rb68D8E2Cy7PlwNJwOAO4DLgsLDMFWEXQkuIvwNcLGN9R4XqXhTFMC6cnx2fAAwStPlYAVQXehp0IDvIHJU2LdfsRJKhNQAPB2dd3gS8DLwNrw7+HhmWrgEeS5r0EWBcOkwoU2zqCuuTGffCXYdkjgHnN7QsF3H7/HO5fywkOcF2bxhiOn0HQ4uadqGJMFV84fWbjfpdUtqDbsJljSiz7n55oFhGRBFUfiYhIgpKCiIgkKCmIiEiCkoKIiCQoKYiISIKSgkjIzHbZnj245q3HTjOrSO6hU6RY7RN3ACJF5DN3Hxx3ECJx0pWCSAZhf/p3mtm/hcP/CKf3NLOXww7fXjazHuH0wy14x8GycPh6uKgyM3s47DP/RTPbLyx/tZm9FS5ndkw/UwRQUhBJtl+T6qOLkr7b5u7DgfuBfwyn3U/QBXklQYd094bT7wUWeNCh37EET8IC9AEecPf+wFbgvHD6jcCQcDmXRfXjRLKhJ5pFQma23d0PSDF9PXCiu78bdlz2X+7+ZTPbTNB1Q0M4fZO7H2ZmdUA3d//vpGVUEPR73yccvwHo6O7/x8z+CGwn6A32eQ87AxSJg64URLLjaT6nK5PKfyd93sXue3rfJuiLaiiwJOy5UyQWSgoi2bko6e+i8PO/EvTqCTABeC38/DJwOYCZlZnZgekWamYdgO7u/grwQ+BgYK+rFZFC0RmJyG772Z4vb/+juzc2S/2Smf2V4ERqfDjtamCGmV0P1AGTwulTgYfM7LsEVwSXE/TQmUoZ8ISZHUTQe+097r41b79IpIV0T0Ekg/CeQpW7b447FpGoqfpIREQSdKUgIiIJulIQEZEEJQUREUlQUhARkQQlBRERSVBSEBGRBCUFERFJ+P8XLmH4PBz8+QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "l2_model_val_loss = l2_model_hist.history['val_loss']\n",
    "\n",
    "plt.plot(epochs, original_val_loss, 'b+', label='Original model')\n",
    "plt.plot(epochs, l2_model_val_loss, 'bo', label='L2-regularized model')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.regularizers.L1L2 at 0x249b6f00400>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keras 中不同的权重正则化项\n",
    "from keras import regularizers\n",
    "# L1 regularization\n",
    "regularizers.l1(0.001)\n",
    "# L1 and L2 regularization at the same time\n",
    "regularizers.l1_l2(l1=0.001, l2=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 添加 dropout 正则化\n",
    "\n",
    "dropout 是神经网络最有效也最常用的正则化方法之一，它是由多伦多大学的 Geoffrey Hinton和他的学生开发的。对某一层使用 dropout，就是在训练过程中随机将该层的一些输出特征舍弃（设置为 0）。假设在训练过程中，某一层对给定输入样本的返回值应该是向量 [0.2, 0.5,1.3, 0.8, 1.1]。使用 dropout 后，这个向量会有几个随机的元素变成 0，比如 [0, 0.5,1.3, 0, 1.1]。 dropout 比率（dropout rate）是被设为 0 的特征所占的比例，通常在 0.2~0.5范围内。测试时没有单元被舍弃，而该层的输出值需要按 dropout 比率缩小，因为这时比训练时有更多的单元被激活，需要加以平衡。\n",
    "\n",
    "假 设 有 一 个 包 含 某 层 输 出 的 Numpy 矩 阵 layer_output， 其 形 状 为 (batch_size,features)。训练时，我们随机将矩阵中一部分值设为\n",
    "\n",
    "```python\n",
    "# 训练时，舍弃 50%的输出单元\n",
    "layer_output *= np.random.randint(0, high=2, size=layer_output.shape)\n",
    "```\n",
    "\n",
    "测试时，我们将输出按 dropout 比率缩小。这里我们乘以 0.5（因为前面舍弃了一半的单元）。\n",
    "```python\n",
    "# 测试时\n",
    "layer_output *= 0.5\n",
    "```\n",
    "\n",
    "注意，为了实现这一过程，还可以让两个运算都在训练时进行，而测试时输出保持不变。这通常也是实践中的实现方式\n",
    "```python\n",
    "# 训练时\n",
    "layer_output *= np.random.randint(0, high=2, size=layer_output.shape) \n",
    "# 注意，是成比例放大而不是成比例缩小\n",
    "layer_output /= 0.5\n",
    "```\n",
    "\n",
    "**训练时对激活矩阵使用 dropout，并在训练时成比例增大。测试时激活矩阵保持不变**\n",
    "\n",
    "![image.png](../img/04/dropout.png)\n",
    "\n",
    "> 它为什么能够降低过拟合？ Hinton 说他的灵感之一来自于银行的防欺诈机制。用他自己的话来说：“我去银行办理业务。柜员不停地换人，于是我问其中一人这是为什么。他说他不知道，但他们经常换来换去。我猜想， 银行工作人员要想成功欺诈银行，他们之间要互相合作才行。这让我意识到，在每个样本中随机删除不同的部分神经元，可以阻止它们的阴谋，因此可以降低过拟合。”其核心思想是在层的输出值中引入噪声，打破不显著的偶然模式（Hinton 称之为阴谋）。如果没有噪声的话，网络将会记住这些偶然模式。\n",
    "\n",
    "在 Keras 中，你可以通过 Dropout 层向网络中引入 dropout， dropout 将被应用于前面一层的输出。\n",
    "\n",
    "```python\n",
    "model.add(layers.Dropout(0.5))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 向 IMDB 网络中添加 dropout\n",
    "# model = models.Sequential()\n",
    "# model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "# model.add(layers.Dropout(0.5))\n",
    "# model.add(layers.Dense(16, activation='relu'))\n",
    "# model.add(layers.Dropout(0.5))\n",
    "# model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# dpt_model_hist = dpt_model.fit(x_train, y_train,\n",
    "#                                epochs=20,\n",
    "#                                batch_size=512,\n",
    "#                                validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dpt_model_val_loss = dpt_model_hist.history['val_loss']\n",
    "\n",
    "# plt.plot(epochs, original_val_loss, 'b+', label='Original model')\n",
    "# plt.plot(epochs, dpt_model_val_loss, 'bo', label='Dropout-regularized model')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Validation loss')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总结一下，防止神经网络过拟合的常用方法包括：\n",
    "* 获取更多的训练数据\n",
    "* 减小网络容量\n",
    "* 添加权重正则化\n",
    "* 添加 dropout"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
