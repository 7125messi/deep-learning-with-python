{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "github：https://github.com/fchollet/deep-learning-with-python-notebooks\n",
    "\n",
    "配置环境：keras 2.2.4（原文是2.0.8，运行结果一致），tensorflow-gpu 1.12.0，python 3.5.4，\n",
    "\n",
    "主机：显卡：一块GTX850M；内存：12G（注：绝大部分代码不需要GPU）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-30T00:59:30.433112Z",
     "start_time": "2018-12-30T00:59:30.425113Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.0'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 初识神经网络\n",
    "\n",
    "* 我们来看一个具体的神经网络示例，使用 Python 的 Keras 库来学习手写数字分类。\n",
    "\n",
    "* 我们这里要解决的问题是，将**手写数字的灰度图像（28 像素×28 像素）划分到 10 个类别中（0~9）**。\n",
    "\n",
    "* 我们将使用 MNIST 数据集，它是机器学习领域的一个经典数据集。这个数据集包含60 000 张训练图像和 10000 张测试图像。你可以将“解决”MNIST 问题看作深度学习的“Hello World”，正是用它来验证你的算法是否按预期运行。\n",
    "\n",
    "### （1）下载数据集，读取数据集\n",
    "\n",
    "这里国内会出现下载不下来，需要先自己下载下来`https://s3.amazonaws.com/img-datasets/mnist.npz`,\n",
    "再放到`C:\\Users\\Administrator\\.keras\\datasets\\`下即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-30T00:50:04.496581Z",
     "start_time": "2018-12-30T00:50:03.632581Z"
    }
   },
   "outputs": [],
   "source": [
    "# 训练和测试\n",
    "from keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* train_images 和 train_labels 组成了训练集（training set），模型将从这些数据中进行学习。\n",
    "* 然后在测试集（test set，即 test_images 和 test_labels）上对模型进行测试。\n",
    "* X:图像被编码为 Numpy 数组，而y标签是数字数组，取值范围为 0~9。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_images.shape)\n",
    "print(train_labels.shape)\n",
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test_images.shape)\n",
    "print(test_labels.shape)\n",
    "test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （2）网络架构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-30T01:07:21.675162Z",
     "start_time": "2018-12-30T01:07:21.569153Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "network.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(network,to_file='./img/02/network.png',show_shapes=True,show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "神经网络的核心组件是层（layer），它是一种数据处理模块，你可以将它看成数据过滤器。 进去一些数据，出来的数据变得更加有用。具体来说，层从输入数据中提取表示——我们期望这种表示有助于解决手头的问题。\n",
    "\n",
    "* 第一层网络包含 2 个 Dense 层，它们是密集连接（也叫全连接）的神经层。\n",
    "* 第二层（也 是最后一层）是一个 10 路 softmax 层，它将返回一个由 10 个概率值（总和为 1）组成的数组。每个概率值表示当前数字图像属于 10 个数字类别中某一个的概率。\n",
    "\n",
    "要想训练网络，我们还需要选择编译（compile）步骤的三个参数。\n",
    "\n",
    "* **损失函数（loss function）：网络如何衡量在训练数据上的性能，即网络如何朝着正确的方向前进。**\n",
    "\n",
    "* **优化器（optimizer）：基于训练数据和损失函数来更新网络的机制。**\n",
    "\n",
    "* **在训练和测试过程中需要监控的指标（metric）：本例只关心精度，即正确分类的图像所占的比例。**\n",
    "\n",
    "### （3）编译步骤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-30T01:07:25.540394Z",
     "start_time": "2018-12-30T01:07:25.458396Z"
    }
   },
   "outputs": [],
   "source": [
    "network.compile(optimizer='rmsprop',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （4）准备X图像数据\n",
    "在开始训练之前，我们将对数据进行预处理，将其变换为网络要求的形状，并缩放到所有值都在 [0, 1] 区间。之前训练图像保存在一个uint8类型的数组中，其形状为 (60000, 28 , 28)，取值区间为 [0, 255]。我们需要将其变换为一个float32数组，其形状为 (60000, 28 * 28)，取值范围为 0~1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-30T01:11:46.310418Z",
     "start_time": "2018-12-30T01:11:45.904419Z"
    }
   },
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （5）准备Y标签，对标签进行分类编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-30T01:13:44.287884Z",
     "start_time": "2018-12-30T01:13:44.263888Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （6）训练数据\n",
    "现在我们准备开始训练网络，在 Keras 中这一步是通过调用网络的 fit 方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 5s 77us/step - loss: 0.2572 - acc: 0.9260\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.1036 - acc: 0.9698\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.0691 - acc: 0.9792\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.0494 - acc: 0.9856: 0s - loss: 0.048\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.0375 - acc: 0.9887\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27f29e04400>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练过程中显示了两个数字：\n",
    "\n",
    "* 一个是网络在训练数据上的损失（loss），\n",
    "\n",
    "* 另一个是网络在训练数据上的精度（acc）。\n",
    "\n",
    "我们很快就在训练数据上达到了 0.989（98.9%）的精度。现在我们来检查一下模型在测试集上的性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 95us/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = network.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 0.9809\n"
     ]
    }
   ],
   "source": [
    "print('test_acc:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试集精度为 97.92%，比训练集精度低不少。训练精度和测试精度之间的这种差距是过拟合（overfit）造成的。过拟合是指机器学习模型在新数据上的性能往往比在训练数据上要差，它 是第 3 章的核心主题。\n",
    "\n",
    "第一个例子到这里就结束了。你刚刚看到了如何构建和训练一个神经网络，用不到 20 行的 Python 代码对手写数字进行分类。下一章会详细介绍这个例子中的每一个步骤，并讲解其背后的原理。接下来你将要学到张量（输入网络的数据存储对象）、张量运算（层的组成要素）和梯度下降（可以让网络从训练样本中进行学习）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 神经网络的数据表示\n",
    "\n",
    "前面数据存储在多维 Numpy 数组中，也叫张量（tensor）。张量这一概念的核心在于，它是一个数据容器。它包含的数据几乎总是数值数据，因此它是数字的容器。你可能对矩阵很熟悉，它是二维张量。张量是矩阵向任意维度的推广［注意，**张量的维度（dimension）通常叫作轴（axis）**］。\n",
    "\n",
    "### 2.2.1 标量（0D 张量）\n",
    "\n",
    "* 仅包含一个数字的张量叫作标量（scalar，也叫标量张量、零维张量、 0D 张量）。\n",
    "\n",
    "* 在 Numpy中，一个 float32 或 float64 的数字就是一个标量张量（或标量数组）。\n",
    "\n",
    "* 可以用 ndim 属性来查看一个 Numpy 张量的轴的个数。\n",
    "\n",
    "* 标量张量有 0 个轴（ndim == 0）。张量轴的个数也叫作阶（rank）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "int32\n",
      "0\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.array(12)\n",
    "print(x)\n",
    "print(x.dtype)\n",
    "print(x.ndim)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 向量（1D 张量）\n",
    "\n",
    "数字组成的数组叫作向量（vector）或一维张量（1D 张量）。一维张量只有一个轴。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12.  3.  6. 14.  7.]\n",
      "float64\n",
      "1\n",
      "(5,)\n"
     ]
    }
   ],
   "source": [
    "x = np.array([12, 3., 6, 14, 7])\n",
    "print(x)\n",
    "print(x.dtype)\n",
    "print(x.ndim)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 矩阵（2D 张量）\n",
    "\n",
    "* 向量组成的数组叫作矩阵（matrix）或二维张量（2D 张量）。\n",
    "\n",
    "* 矩阵有 2 个轴（通常叫作行和列）。\n",
    "\n",
    "* 第一个轴上的元素叫作行（row），第二个轴上的元素叫作列（column）。\n",
    "\n",
    "* 在下面的例子中，`[5, 78, 2, 34, 0]`是x的第一行， `[5, 6, 7]`是第一列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5 78  2 34  0]\n",
      " [ 6 79  3 35  1]\n",
      " [ 7 80  4 36  2]]\n",
      "int32\n",
      "2\n",
      "(3, 5)\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[5, 78, 2, 34, 0],\n",
    "              [6, 79, 3, 35, 1],\n",
    "              [7, 80, 4, 36, 2]])\n",
    "print(x)\n",
    "print(x.dtype)\n",
    "print(x.ndim)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.4 3D 张量与更高维张量\n",
    "\n",
    "将多个矩阵组合成一个新的数组，可以得到一个 3D 张量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 5. 78.  2. 34.  0.]\n",
      "  [ 6. 79.  3. 35.  1.]\n",
      "  [ 7. 80.  4. 36.  2.]]\n",
      "\n",
      " [[ 5. 78.  2. 34.  0.]\n",
      "  [ 6. 79.  3. 35.  1.]\n",
      "  [ 7. 80.  4. 36.  2.]]\n",
      "\n",
      " [[ 5. 78.  2. 34.  0.]\n",
      "  [ 6. 79.  3. 35.  1.]\n",
      "  [ 7. 80.  4. 36.  2.]]]\n",
      "float64\n",
      "3\n",
      "(3, 3, 5)\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[[5, 78, 2, 34, 0],\n",
    "               [6, 79, 3, 35, 1],\n",
    "               [7, 80, 4, 36, 2]],\n",
    "              [[5, 78, 2, 34, 0],\n",
    "               [6, 79, 3, 35, 1],\n",
    "               [7, 80, 4, 36, 2]],\n",
    "              [[5, 78, 2, 34, 0],\n",
    "               [6, 79, 3, 35, 1],\n",
    "               [7, 80, 4., 36, 2]]])\n",
    "print(x)\n",
    "print(x.dtype)\n",
    "print(x.ndim)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 将多个`3D`张量组合成一个数组，可以创建一个`4D`张量，以此类推。\n",
    "\n",
    "* 深度学习处理的一般是`0D`到`4D`的张量，但处理视频数据时可能会遇到`5D`张量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.5 关键属性\n",
    "\n",
    "张量是由以下三个关键属性来定义的。\n",
    "\n",
    "* 轴的个数（阶）`ndim`。例如， 3D 张量有 3 个轴，矩阵有 2 个轴。这在 Numpy 等 Python 库中也叫张量的 ndim。\n",
    "\n",
    "* 形状`shape`。这是一个整数元组，表示张量沿每个轴的维度大小（元素个数）。例如，前面矩阵示例的形状为 (3, 5)， 3D 张量示例的形状为 (3, 3, 5)。向量的形状只包含一个元素，比如 (5,)，而标量的形状为空，即 ()。\n",
    "\n",
    "* 数据类型（在 Python 库中通常叫作 `dtype`）。这是张量中所包含数据的类型，例如，张量的类型可以是 `float32`、 `uint8`、 `float64`等。在极少数情况下，你可能会遇到字符（`char`）张量。注意， Numpy（以及大多数其他库）中不存在字符串张量，因为**张量存储在预先分配的连续内存段中，而字符串的长度是可变的，无法用这种方式存储。**\n",
    "\n",
    "这里 `train_images` 是一个由 8 位整数组成的 3D 张量。更确切地说，它是 60000个矩阵组成的数组，每个矩阵由 `28×28` 个整数组成。每个这样的矩阵都是一张灰度图像，元素取值范围为 `0~255`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "1\n",
      "3\n",
      "1\n",
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "uint8\n",
      "uint8\n",
      "uint8\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "print(train_images.ndim)\n",
    "print(train_labels.ndim)\n",
    "print(train_images.ndim)\n",
    "print(train_labels.ndim)\n",
    "\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)\n",
    "\n",
    "print(train_images.dtype)\n",
    "print(train_labels.dtype)\n",
    "print(train_images.dtype)\n",
    "print(train_labels.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# （训练、验证和测试）\n",
    "# from tensorflow.examples.tutorials.mnist import input_data\n",
    "# mnist = input_data.read_data_sets('./mnist/', one_hot=True)\n",
    "\n",
    "# 读取一张 mnist.train.images 里的图片\n",
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# temp = mnist.train.images[4]\n",
    "# img=np.reshape(temp, (28, 28))\n",
    "# plt.imshow(img,cmap='gray')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 读取一张train_images里的图片\n",
    "%matplotlib inline\n",
    "digit = train_images[4]\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(digit, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(digit, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.6 在Numpy中操作张量\n",
    "\n",
    "使用语法 `train_images[i]` 来选择沿着第一个轴的特定数字。选择张量的特定元素叫作张量切片（`tensor slicing`）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  55,\n",
       "        148, 210, 253, 253, 113,  87, 148,  55,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  87, 232,\n",
       "        252, 253, 189, 210, 252, 252, 253, 168,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,  57, 242, 252,\n",
       "        190,  65,   5,  12, 182, 252, 253, 116,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  96, 252, 252, 183,\n",
       "         14,   0,   0,  92, 252, 252, 225,  21,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 132, 253, 252, 146,  14,\n",
       "          0,   0,   0, 215, 252, 252,  79,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 126, 253, 247, 176,   9,   0,\n",
       "          0,   8,  78, 245, 253, 129,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  16, 232, 252, 176,   0,   0,   0,\n",
       "         36, 201, 252, 252, 169,  11,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  22, 252, 252,  30,  22, 119, 197,\n",
       "        241, 253, 252, 251,  77,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  16, 231, 252, 253, 252, 252, 252,\n",
       "        226, 227, 252, 231,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  55, 235, 253, 217, 138,  42,\n",
       "         24, 192, 252, 143,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         62, 255, 253, 109,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         71, 253, 252,  21,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0, 253, 252,  21,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         71, 253, 252,  21,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        106, 253, 252,  21,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         45, 255, 253,  21,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0, 218, 252,  56,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  96, 252, 189,  42,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  14, 184, 252, 170,  11,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  14, 147, 252,  42,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 28, 28)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 选择第 10~100 个数字（不包括第 100 个），并将其放在形状为 (90, 28,28) 的数组中\n",
    "my_slice = train_images[10:100]\n",
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 28, 28)\n",
      "(90, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# 切片沿着每个张量轴的起始索引和结束索引。注意， : 等同于选择整个轴。\n",
    "my_slice = train_images[10:100, :, :]\n",
    "print(my_slice.shape)\n",
    "\n",
    "my_slice = train_images[10:100, 0:28, 0:28]\n",
    "print(my_slice.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一般来说，你可以沿着每个张量轴在任意两个索引之间进行选择。\n",
    "\n",
    "例如，你可以在所有图像的右下角选出 14 像素×14 像素的区域。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 14, 14)\n"
     ]
    }
   ],
   "source": [
    "my_slice = train_images[:, 14:, 14:]\n",
    "print(my_slice.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.7 数据批量\n",
    "\n",
    "* 通常来说，深度学习中所有数据张量的第一个轴（0 轴，因为索引从 0 开始）都是样本轴（samples axis，有时也叫样本维度）。在 MNIST 的例子中，样本就是数字图像。\n",
    "\n",
    "* 此外，深度学习模型不会同时处理整个数据集，而是将数据拆分成小批量。具体来看，下面是 MNIST 数据集的一个批量，批量大小为 128。\n",
    "\n",
    "```\n",
    "batch = train_images[:128]\n",
    "\n",
    "batch = train_images[128:256]\n",
    "...\n",
    "batch = train_images[128 * n:128 * (n + 1)]\n",
    "```\n",
    "\n",
    "* 对于这种批量张量，第一个轴（0 轴）叫作批量轴（batch axis）或批量维度（batch dimension）。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.8 现实世界中的数据张量\n",
    "\n",
    "你需要处理的数据几乎总是以下类别之一。\n",
    "* 向量数据： 2D 张量，形状为 `(samples, features)`。\n",
    "* 时间序列数据或序列数据： 3D 张量，形状为 `(samples, timesteps, features)`。\n",
    "* 图像： 4D 张量，形状为 `(samples, height, width, channels)` 或 `(samples, channels,height, width)`。\n",
    "* 视频： 5D 张量，形状为 `(samples, frames, height, width, channels)` 或 `(samples,frames, channels, height, width)`。\n",
    "\n",
    "#### （1）向量数据\n",
    "\n",
    "最常见的数据。对于这种数据集，每个数据点都被编码为一个向量，因此一个数据批量就被编码为 2D 张量（即向量组成的数组），其中第一个轴是样本轴，第二个轴是特征轴。\n",
    "\n",
    "#### （2）时间序列数据或序列数据\n",
    "\n",
    "当时间（或序列顺序）对于数据很重要时，应该将数据存储在带有时间轴的 3D 张量中。每个样本可以被编码为一个向量序列（即 2D 张量），因此一个数据批量就被编码为一个 3D 张量。\n",
    "\n",
    "![image.png](../img/02/时间序列数据.png)\n",
    "\n",
    "根据惯例，时间轴始终是第 2 个轴（索引为 1 的轴）。我们来看几个例子。\n",
    "\n",
    "* 股票价格数据集。每一分钟，我们将股票的当前价格、前一分钟的最高价格和前一分钟的最低价格保存下来。因此每分钟被编码为一个 3D 向量，整个交易日被编码为一个形状为 (390, 3) 的 2D 张量（一个交易日有 390 分钟），而 250 天的数据则可以保存在一个形状为 (250, 390, 3) 的 3D 张量中。这里每个样本是一天的股票数据。\n",
    "\n",
    "* 推文数据集。我们将每条推文编码为 280 个字符组成的序列，而每个字符又来自于 128个字符组成的字母表。在这种情况下，每个字符可以被编码为大小为 128 的二进制向量（只有在该字符对应的索引位置取值为 1，其他元素都为 0）。那么每条推文可以被编码为一个形状为 (280, 128) 的 2D 张量，而包含 100 万条推文的数据集则可以存储在一个形状为 (1000000, 280, 128) 的张量中。\n",
    "\n",
    "#### （3）图像数据\n",
    "\n",
    "图像通常具有三个维度：高度、宽度和颜色深度。虽然灰度图像（比如 MNIST 数字图像）只有一个颜色通道，因此可以保存在 2D 张量中，但按照惯例，图像张量始终都是 3D 张量，灰度图像的彩色通道只有一维。因此，如果图像大小为 256×256，那么 128 张灰度图像组成的批量可以保存在一个形状为 (128, 256, 256, 1) 的张量中，而 128 张彩色图像组成的批量则可以保存在一个形状为 (128, 256, 256, 3) 的张量中。\n",
    "![image.png](../img/02/图像数据.png)\n",
    "\n",
    "图像张量的形状有两种约定： \n",
    "* 通道在后（channels-last）的约定（在 TensorFlow 中使用）\n",
    "* 通道在前（channels-first）的约定（在 Theano 中使用）\n",
    "* TensorFlow 机器学习框架将颜色深度轴放在最后： `(samples, height, width, color_depth)`\n",
    "* Theano将图像深度轴放在批量轴之后： `(samples, color_depth, height, width)`\n",
    "* Keras 框架同时支持这两种格式\n",
    "    * TensorFlow作为后端形式：`C:\\Users\\Administrator\\.keras\\keras.json`\n",
    "    ```json\n",
    "    {\n",
    "    \"epsilon\": 1e-07,\n",
    "    \"floatx\": \"float32\",\n",
    "    \"backend\": \"tensorflow\",\n",
    "    \"image_data_format\": \"channels_last\"\n",
    "    }\n",
    "    ```\n",
    "\n",
    "#### （4）视频数据\n",
    "\n",
    "* 视频数据是现实生活中需要用到 5D 张量的少数数据类型之一。\n",
    "* 视频可以看作`一系列帧`，`每一帧`都是`一张彩色图像`。\n",
    "* 由于`每一帧`都可以保存在一个形状为 `(height, width, color_depth)` 的 3D 张量中，因此`一系列帧`可以保存在一个形状为 `(frames, height, width,color_depth)` 的 4D 张量中，而`不同视频组成的批量`则可以保存在一个 5D 张量中，其形状为`(samples, frames, height, width, color_depth)`。\n",
    "\n",
    "* 一个以`每秒 4 帧`采样的 `60 秒` YouTube 视频片段，视频尺寸为 `144×256`，这个视频共有 `240 帧`。 `4 个这样的视频片段`组成的批量将保存在形状为 `(4, 240, 144, 256, 3)`的张量中。总共有`106168320个`值。\n",
    "* 如果张量的数据类型（`dtype`）是 `float32`，每个值都是`32`位，那么这个张量共有`405MB`。好大！你在现实生活中遇到的视频要小得多，因为它们不以`float32`格式存储，而且通常被大大压缩，比如`MPEG`格式。\n",
    "\n",
    "## 2.3 神经网络的“齿轮”：张量运算\n",
    "\n",
    "所有计算机程序最终都可以简化为二进制输入上的一些二进制运算（AND、 OR、 NOR 等），与此类似，深度神经网络学到的所有变换也都可以简化为数值数据张量上的一些张量运算（tensor operation），例如加上张量、乘以张量等。\n",
    "\n",
    "**例如:**\n",
    "\n",
    "我们通过叠加 Dense 层来构建网络。\n",
    "```\n",
    "keras.layers.Dense(512, activation='relu')\n",
    "```\n",
    "这个层可以理解为一个函数，输入一个 2D 张量，返回另一个 2D 张量，即输入张量的新表示。具体而言，这个函数如下所示（其中 W 是一个 2D 张量， b 是一个向量，二者都是该层的属性）。\n",
    "```\n",
    "output = relu(dot(W, input) + b)\n",
    "```\n",
    "这里有三个张量运算：\n",
    "* 输入张量和张量W之间的点积运算（dot）、\n",
    "* 得到的 2D 张量与向量 b 之间的加法运算（+）、\n",
    "* 最后的 relu 运算(relu(x) 是 max(x, 0))\n",
    "\n",
    "### 2.3.1 逐元素运算\n",
    "\n",
    "* `relu`运算和加法都是`逐元素（element-wise）`的运算，即该运算`独立地应用于张量中的每个元素`，也就是说，这些运算非常适合大规模并行实现（向量化实现）。\n",
    "\n",
    "![image.png](../img/02/逐元素运算.png)\n",
    "\n",
    "* 在实践中处理 Numpy 数组时，这些运算都是优化好的 Numpy 内置函数\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "z = x + y\n",
    "z = np.maximum(z, 0.)\n",
    "```\n",
    "\n",
    "### 2.3.2 广播\n",
    "\n",
    "如果将两个形状不同的张量相加，会发生什么？\n",
    "**如果没有歧义的话，较小的张量会被广播（broadcast），以匹配较大张量的形状。**\n",
    "\n",
    "广播包含：\n",
    "\n",
    "* (1) 向较小的张量添加轴（叫作广播轴），使其 ndim 与较大的张量相同。\n",
    "\n",
    "* (2) 将较小的张量沿着新轴重复，使其形状与较大的张量相同。\n",
    "\n",
    "```python\n",
    "def naive_add_matrix_and_vector(x, y):\n",
    "    assert len(x.shape) == 2\n",
    "    assert len(y.shape) == 1\n",
    "    assert x.shape[1] == y.shape[0]\n",
    "    x = x.copy()\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i, j] += y[j]\n",
    "    return x\n",
    "```\n",
    "```python\n",
    "import numpy as np\n",
    "x = np.random.random((64, 3, 32, 10))\n",
    "y = np.random.random((32, 10))\n",
    "z = np.maximum(x, y)\n",
    "```\n",
    "\n",
    "### 2.3.3 张量点积\n",
    "\n",
    "* 在 `Numpy`、 `Keras`、`TensorFlow`中，都是用 `*` 实现逐元素乘积。\n",
    "\n",
    "* `TensorFlow`中的点积使用了不同的语法，但在 `Numpy`和`Keras`中，都是用标准的`dot`运算符来实现点积。\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "z = np.dot(x, y)\n",
    "```\n",
    "\n",
    "```python\n",
    "# 两个向量 x 和 y 的点积\n",
    "def naive_vector_dot(x, y):\n",
    "    assert len(x.shape) == 1\n",
    "    assert len(y.shape) == 1\n",
    "    assert x.shape[0] == y.shape[0]\n",
    "    z = 0.\n",
    "    for i in range(x.shape[0]):\n",
    "        z += x[i] * y[i]\n",
    "    return z\n",
    "```\n",
    "> 注意，两个向量之间的点积是一个标量，而且只有元素个数相同的向量之间才能做点积。\n",
    "\n",
    "```python\n",
    "# 对一个矩阵 x 和一个向量 y 做点积，返回值是一个向量，其中每个元素是 y 和 x的每一行之间的点积\n",
    "import numpy as np\n",
    "def naive_matrix_vector_dot(x, y):\n",
    "    assert len(x.shape) == 2\n",
    "    assert len(y.shape) == 1\n",
    "    assert x.shape[1] == y.shape[0]\n",
    "    z = np.zeros(x.shape[0])\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            z[i] += x[i, j] * y[j]\n",
    "    return z\n",
    "```\n",
    "\n",
    "```python\n",
    "# 矩阵 - 向量点积与向量点积之间的关系\n",
    "def naive_matrix_vector_dot(x, y):\n",
    "    z = np.zeros(x.shape[0])\n",
    "    for i in range(x.shape[0]):\n",
    "        z[i] = naive_vector_dot(x[i, :], y)\n",
    "    return z\n",
    "```\n",
    "> 注意，如果两个张量中有一个的 ndim 大于 1，那么 dot 运算就不再是对称的，也就是说，dot(x, y) 不等于 dot(y, x)。\n",
    "\n",
    "点积可以推广到具有任意个轴的张量。最常见的应用可能就是**两个矩阵之间的点积**。对于两个矩阵 `x` 和 `y`，当且仅当 `x.shape[1] == y.shape[0]`时，你才可以对它们做点积（`dot(x, y)`）。得到的结果是一个形状为 `(x.shape[0], y.shape[1])`的矩阵，其元素为`x`的行与`y`的列之间的点积。\n",
    "\n",
    "```python\n",
    "# 两个矩阵之间的点积\n",
    "def naive_matrix_dot(x, y):\n",
    "    assert len(x.shape) == 2\n",
    "    assert len(y.shape) == 2\n",
    "    assert x.shape[1] == y.shape[0]\n",
    "    \n",
    "    z = np.zeros((x.shape[0], y.shape[1]))\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(y.shape[1]):\n",
    "            row_x = x[i, :]\n",
    "            column_y = y[:, j]\n",
    "            z[i, j] = naive_vector_dot(row_x, column_y)\n",
    "    return z\n",
    "```\n",
    "\n",
    "![image.png](../img/02/图解矩阵点积.png)\n",
    "\n",
    "\n",
    "\n",
    "### 2.3.4 张量变形\n",
    "\n",
    "图像数据输入神经网络之前，我们在预处理时用到了这个运算。\n",
    "\n",
    "```python\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "```\n",
    "一种特殊的张量变形是转置（`transposition`）。对矩阵做转置是指将行和列互换，使 `x[i, :]` 变为 `x[:, i]`\n",
    "\n",
    "```python\n",
    "x = np.zeros((300, 20))\n",
    "x = np.transpose(x)\n",
    "x.shape\n",
    "(20, 300)\n",
    "```\n",
    "\n",
    "### 2.3.5 张量运算的几何解释\n",
    "\n",
    "数学，线性代数中：向量加法\n",
    "\n",
    "\n",
    "### 2.3.6 深度学习的几何解释\n",
    "\n",
    "神经网络完全由一系列张量运算组成，而这些**张量运算都只是输入数据的几何变换**。因此，你可以**将神经网络解释为高维空间中非常复杂的几何变换，这种变换可以通过许多简单的步骤来实现**。\n",
    "\n",
    "**非常形象的比喻**\n",
    "* 对于三维的情况，下面这个思维图像是很有用的。想象有两张彩纸：**一张红色，一张蓝色**\n",
    "\n",
    "* 将其中一张纸放在另一张上。现在将两张纸一起揉成小球。**这个皱巴巴的纸球就是你的输入数据**，**每张纸对应于分类问题中的一个类别**。神经网络（或者任何机器学习模型）要做的就是**找到可以让纸球恢复平整的变换，从而能够再次让两个类别明确可分**。通过深度学习，这一过程可以用三维空间中一系列简单的变换来实现，比如你用手指对纸球做的变换，每次做一个动作。\n",
    "\n",
    "![image.png](../img/02/解开复杂的数据流形.png)\n",
    "\n",
    "* 让纸球恢复平整就是机器学习的内容：**为复杂的、高度折叠的数据流形找到简洁的表示**。现在你应该能够很好地理解，为什么深度学习特别擅长这一点：**它将复杂的几何变换逐步分解为一长串基本的几何变换，这与人类展开纸球所采取的策略大致相同**。深度网络的每一层都通过变换使数据解开一点点——许多层堆叠在一起，可以实现非常复杂的解开过程。\n",
    "\n",
    "## 2.4 神经网络的“引擎”：基于梯度的优化\n",
    "\n",
    "沿着梯度的反方向更新权重，损失每次都会变小一点。\n",
    "* (1) 抽取训练样本 `x` 和对应目标 `y` 组成的数据批量。\n",
    "* (2) 在 x 上运行网络，得到预测值 `y_pred`。\n",
    "* (3) 计算网络在这批数据上的损失，用于衡量 `y_pred` 和 `y` 之间的距离。\n",
    "* (4) 计算损失相对于网络参数的梯度［一次反向传播（`backward pass`）］。\n",
    "* (5) 将参数沿着梯度的反方向移动一点，比如 `W -= step * gradient`，从而使这批数据上的损失减小一点。\n",
    "\n",
    "**小批量随机梯度下降（`mini-batch stochastic gradient descent`**，又称为**小批量SGD**）。随机（`stochastic`）是指每批数据都是随机抽取的。下图给出了一维的情况，网络只有一个参数，并且只有一个训练样本。\n",
    "\n",
    "![image.png](../img/02/一维参数空间中的梯度下降.png)\n",
    "\n",
    "* 为`step`因子选取合适的值是很重要的。如果取值太小，则沿着曲线的下降需要很多次迭代，而且可能会陷入局部极小点。如果取值太大，则更新权重值之后可能会出现在曲线上完全随机的位置。\n",
    "* **小批量SGD算法**的一个变体是**每次迭代时只抽取一个样本和目标，而不是抽取一批数据**。 这叫作**真SGD（有别于小批量 SGD）**。还有另一种极端，**每一次迭代都在所有数据上运行，这叫作批量SGD**。这样做的话，每次更新都更加准确，但计算代价也高得多。这两个极端之间的有效折中则是选择合理的批量大小。\n",
    "* 上图是一维参数空间中的梯度下降，但在实践中需要在**高维空间中使用梯度下降**。神经网络的每一个权重参数都是空间中的一个自由维度，网络中可能包含数万个甚至上百万个参数维度。为了让你对损失曲面有更直观的认识，你还可以将梯度下降沿着二维损失曲面可视化。但你不可能将神经网络的实际训练过程可视化，因为你无法用人类可以理解的方式来可视化`1000000`维空间。\n",
    "\n",
    "![image.png](../img/02/二维参数空间中的梯度下降.png)\n",
    "\n",
    "* SGD还有多种变体，其区别**在于计算下一次权重更新时还要考虑上一次权重更新，而不是仅仅考虑当前梯度值**，比如**带动量的SGD、 Adagrad、 RMSProp 等变体**。这些变体被称为**优化方法（optimization method）或优化器（optimizer）**。其中**动量的概念**尤其值得关注，它在许多变体中都有应用。\n",
    "\n",
    "* **动量解决了 SGD 的两个问题：收敛速度和局部极小点**。\n",
    "\n",
    "![image.png](../img/02/局部极小点和全局最小点.png)\n",
    "\n",
    "* 在某个参数值附近，有一个**局部极小点（local minimum）**：在这个点附近，向左移动和向右移动都会导致损失值增大。如果使用小学习率的`SGD`进行优化，那么优化过程可能会陷入局部极小点，导致无法找到全局最小点。\n",
    "\n",
    "* 使用动量方法可以避免这样的问题，这一方法的灵感来源于物理学。将**优化过程想象成一个小球从损失函数曲线上滚下来**。**如果小球的动量足够大，那么它不会卡在峡谷里，最终会到达全局最小点**。动量方法的实现过程是**每一步都移动小球，不仅要考虑当前的斜率值（当前的加速度），还要考虑当前的速度（来自于之前的加速度）**。这在实践中的是指，更新参数 `w` 不仅要考虑当前的梯度值，还要考虑上一次的参数更新。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
